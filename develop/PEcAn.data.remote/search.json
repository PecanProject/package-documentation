[{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mike Dietze. Author. Bailey Morrison. Author, maintainer. University Illinois, NCSA. Copyright holder.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Dietze M, Morrison B (2025). PEcAn.data.remote: PEcAn Functions Used Extracting Remote Sensing Data. R package version 1.9.1, https://pecanproject.github.io.","code":"@Manual{,   title = {PEcAn.data.remote: PEcAn Functions Used for Extracting Remote Sensing Data},   author = {Mike Dietze and Bailey Morrison},   year = {2025},   note = {R package version 1.9.1},   url = {https://pecanproject.github.io}, }"},{"path":"/index.html","id":"pecandataremote","dir":"","previous_headings":"","what":"PEcAn Functions Used for Extracting Remote Sensing Data","title":"PEcAn Functions Used for Extracting Remote Sensing Data","text":"PEcAn Functions Used Extracting Remote Sensing Data","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"PEcAn Functions Used for Extracting Remote Sensing Data","text":"can install development version PEcAn.data.remote r-universe like : can install directly GitHub remotes package like :","code":"# Enable repository from pecanproject options(repos = c(   pecanproject = 'https://pecanproject.r-universe.dev',   CRAN = 'https://cloud.r-project.org')) # Download and install PEcAn.data.remote in R install.packages('PEcAn.data.remote') library(remotes) install_github('pecanproject/pecan',  subdir = \"modules/data.remote\")"},{"path":"/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"PEcAn Functions Used for Extracting Remote Sensing Data","text":"basic example shows solve common problem:","code":"library(PEcAn.data.remote) ## basic example code"},{"path":"/reference/GEDI_AGB_prep.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare L4A GEDI above ground biomass (AGB) data for the state data assimilation (SDA) workflow. — GEDI_AGB_prep","title":"Prepare L4A GEDI above ground biomass (AGB) data for the state data assimilation (SDA) workflow. — GEDI_AGB_prep","text":"Prepare L4A GEDI ground biomass (AGB) data state data assimilation (SDA) workflow.","code":""},{"path":"/reference/GEDI_AGB_prep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare L4A GEDI above ground biomass (AGB) data for the state data assimilation (SDA) workflow. — GEDI_AGB_prep","text":"","code":"GEDI_AGB_prep(   site_info,   time_points,   outdir = file.path(getwd(), \"GEDI_AGB\"),   buffer = 0.005,   search_window = \"6 month\",   bbox = NULL,   batch = FALSE,   prerun = NULL,   num.folder = NULL,   cores = parallel::detectCores(),   credential_path = \"~/.netrc\" )"},{"path":"/reference/GEDI_AGB_prep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare L4A GEDI above ground biomass (AGB) data for the state data assimilation (SDA) workflow. — GEDI_AGB_prep","text":"site_info List: list including site_id, longitude, latitude. time_points Character: vector date contains target dates (YYYY-MM-DD). outdir Character: Directory final CSV file stored. buffer Numeric: buffer distance (degrees) locate GEDI AGB searching box (default 0.005 [~ 500 m]). search_window Character: search window (length time. e.g., 6 month) locate available GEDI AGB values. bbox Numeric: vector (xmin, xmax, ymin, ymax) covers sites site_info object (default NULL). batch Boolean: determine want submit jobs queue (default FALSE). prerun Character: series pre-launch shell command running shell job (default NULL). num.folder Numeric: number batch folders created submitting jobs queue. cores Numeric: numbers core used parallel computation. default maximum current CPU number. credential_path Character: physical path credential file. (.netrc).","code":""},{"path":"/reference/GEDI_AGB_prep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare L4A GEDI above ground biomass (AGB) data for the state data assimilation (SDA) workflow. — GEDI_AGB_prep","text":"data frame containing AGB sd site time step.","code":""},{"path":"/reference/GEDI_AGB_prep.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prepare L4A GEDI above ground biomass (AGB) data for the state data assimilation (SDA) workflow. — GEDI_AGB_prep","text":"first use, users need create  `.nasadaacapirc` file folder first second lines  username password NASA Earth Explore server.  account, register https://urs.earthdata.nasa.gov/users/new.","code":""},{"path":"/reference/GEDI_AGB_prep.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prepare L4A GEDI above ground biomass (AGB) data for the state data assimilation (SDA) workflow. — GEDI_AGB_prep","text":"Dongchen Zhang","code":""},{"path":"/reference/GEDI_AGB_prep.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare L4A GEDI above ground biomass (AGB) data for the state data assimilation (SDA) workflow. — GEDI_AGB_prep","text":"","code":"if (FALSE) { # \\dontrun{ settings <- PEcAn.settings::read.settings(\"pecan.xml\") site_info <- settings %>%    purrr::map(~.x[['run']] ) %>%    purrr::map('site')%>%    purrr::map(function(site.list){     #conversion from string to number     site.list$lat <- as.numeric(site.list$lat)     site.list$lon <- as.numeric(site.list$lon)     list(site_id=site.list$id, lat=site.list$lat, lon=site.list$lon, site_name=site.list$name)   }) %>%    dplyr::bind_rows() %>%    as.list() time_points <- seq(start.date, end.date, by = time.step) buffer <- 0.005 outdir <- getwd() GEDI_AGB <- GEDI_AGB_prep(site_info, time_points, outdir, buffer) } # }"},{"path":"/reference/GEDI_L4A_2_mean_var.batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Submit jobs through `qsub` for the `GEDI_L4A_2_mean_var` function. — GEDI_L4A_2_mean_var.batch","title":"Submit jobs through `qsub` for the `GEDI_L4A_2_mean_var` function. — GEDI_L4A_2_mean_var.batch","text":"Submit jobs `qsub` `GEDI_L4A_2_mean_var` function.","code":""},{"path":"/reference/GEDI_L4A_2_mean_var.batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Submit jobs through `qsub` for the `GEDI_L4A_2_mean_var` function. — GEDI_L4A_2_mean_var.batch","text":"","code":"GEDI_L4A_2_mean_var.batch(   site_info,   outdir,   which.point.in.which.file,   num.folder,   buffer = 0.005,   cores = parallel::detectCores(),   prerun = NULL )"},{"path":"/reference/GEDI_L4A_2_mean_var.batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Submit jobs through `qsub` for the `GEDI_L4A_2_mean_var` function. — GEDI_L4A_2_mean_var.batch","text":"site_info List: list site info including site_id, site_name, lon, lat. outdir Character: physical path within batch job folders created. .point...file List: lists containing physical paths GEDI tiles intercept site. num.folder Numeric: number batch folders created. buffer Numeric: buffer distance (degree) used create bounding box (default 0.005 [~ 500 m]). cores Numeric: numbers core used parallel computation. default maximum current CPU number. prerun Character: vector strings executed beforehand. default NULL.","code":""},{"path":"/reference/GEDI_L4A_2_mean_var.batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Submit jobs through `qsub` for the `GEDI_L4A_2_mean_var` function. — GEDI_L4A_2_mean_var.batch","text":"list containing AGB mean standard devieation site.","code":""},{"path":"/reference/GEDI_L4A_2_mean_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate AGB mean and uncertainty from the GEDI level4A tiles. — GEDI_L4A_2_mean_var","title":"Aggregate AGB mean and uncertainty from the GEDI level4A tiles. — GEDI_L4A_2_mean_var","text":"Aggregate AGB mean uncertainty GEDI level4A tiles.","code":""},{"path":"/reference/GEDI_L4A_2_mean_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate AGB mean and uncertainty from the GEDI level4A tiles. — GEDI_L4A_2_mean_var","text":"","code":"GEDI_L4A_2_mean_var(   site_info,   which.point.in.which.file,   buffer = 0.005,   cores = parallel::detectCores() )"},{"path":"/reference/GEDI_L4A_2_mean_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate AGB mean and uncertainty from the GEDI level4A tiles. — GEDI_L4A_2_mean_var","text":"site_info List: list site info including site_id, site_name, lon, lat. .point...file List: lists containing physical paths GEDI tiles intercept site. buffer Numeric: buffer distance (degree) used create bounding box (default 0.005 [~ 500 m]). cores Numeric: numbers core used parallel computation. default maximum current CPU number.","code":""},{"path":"/reference/GEDI_L4A_2_mean_var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate AGB mean and uncertainty from the GEDI level4A tiles. — GEDI_L4A_2_mean_var","text":"list containing AGB mean standard deviation site.","code":""},{"path":"/reference/GEDI_L4A_Finder.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect which GEDI level 4A tiles intercept which site. — GEDI_L4A_Finder","title":"Detect which GEDI level 4A tiles intercept which site. — GEDI_L4A_Finder","text":"Detect GEDI level 4A tiles intercept site.","code":""},{"path":"/reference/GEDI_L4A_Finder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect which GEDI level 4A tiles intercept which site. — GEDI_L4A_Finder","text":"","code":"GEDI_L4A_Finder(   files,   site_info,   buffer = 0.005,   cores = parallel::detectCores() )"},{"path":"/reference/GEDI_L4A_Finder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect which GEDI level 4A tiles intercept which site. — GEDI_L4A_Finder","text":"files Character: full paths GEDI level 4A tiles. site_info List: list site info including site_id, site_name, lon, lat. buffer Numeric: buffer distance (degree) used create bounding box (default 0.005 [~ 500 m]). cores Numeric: numbers core used parallel computation. default maximum current CPU number.","code":""},{"path":"/reference/GEDI_L4A_Finder.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect which GEDI level 4A tiles intercept which site. — GEDI_L4A_Finder","text":"list containing physical paths GEDI tiles intercept site.","code":""},{"path":"/reference/GEDI_L4A_Finder_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Submit jobs through `qsub` for the `GEDI_L4A_Finder` function. — GEDI_L4A_Finder_batch","title":"Submit jobs through `qsub` for the `GEDI_L4A_Finder` function. — GEDI_L4A_Finder_batch","text":"Submit jobs `qsub` `GEDI_L4A_Finder` function.","code":""},{"path":"/reference/GEDI_L4A_Finder_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Submit jobs through `qsub` for the `GEDI_L4A_Finder` function. — GEDI_L4A_Finder_batch","text":"","code":"GEDI_L4A_Finder_batch(   files,   outdir,   site_info,   num.folder,   buffer = 0.005,   cores = parallel::detectCores(),   prerun = NULL )"},{"path":"/reference/GEDI_L4A_Finder_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Submit jobs through `qsub` for the `GEDI_L4A_Finder` function. — GEDI_L4A_Finder_batch","text":"files Character: full paths GEDI level 4A tiles. outdir Character: physical path within batch job folders created. site_info List: list site info including site_id, site_name, lon, lat. num.folder Numeric: number batch folders created. buffer Numeric: buffer distance (degree) used create bounding box (default 0.005 [~ 500 m]). cores Numeric: numbers core used parallel computation. default maximum current CPU number. prerun Character: vector strings executed beforehand. default NULL.","code":""},{"path":"/reference/GEDI_L4A_Finder_batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Submit jobs through `qsub` for the `GEDI_L4A_Finder` function. — GEDI_L4A_Finder_batch","text":"list containing physical paths GEDI tiles intercept site.","code":""},{"path":"/reference/Landtrendr_AGB_prep.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare Landtrendr AGB data for the SDA workflow. — Landtrendr_AGB_prep","title":"Prepare Landtrendr AGB data for the SDA workflow. — Landtrendr_AGB_prep","text":"Prepare Landtrendr AGB data SDA workflow.","code":""},{"path":"/reference/Landtrendr_AGB_prep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare Landtrendr AGB data for the SDA workflow. — Landtrendr_AGB_prep","text":"","code":"Landtrendr_AGB_prep(   site_info,   start_date,   end_date,   time_points,   AGB_indir,   outdir = NULL,   export_csv = TRUE,   allow_download = FALSE,   buffer = NULL,   skip_buffer = TRUE )"},{"path":"/reference/Landtrendr_AGB_prep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare Landtrendr AGB data for the SDA workflow. — Landtrendr_AGB_prep","text":"site_info Bety list site info including site_id, site_name, lon, lat. start_date Start date SDA workflow. end_date End date SDA workflow. time_points vector contains time point within start end date. AGB_indir Landtrendr AGB data can accessed. outdir final CSV file stored. export_csv Decide want export CSV file. allow_download data missing, download missing data? buffer buffer area calculate min var AGB data. skip_buffer flag skip calculating min var based buffer area.","code":""},{"path":"/reference/Landtrendr_AGB_prep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare Landtrendr AGB data for the SDA workflow. — Landtrendr_AGB_prep","text":"data frame containing AGB median sd site time step.","code":""},{"path":"/reference/Landtrendr_AGB_prep.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prepare Landtrendr AGB data for the SDA workflow. — Landtrendr_AGB_prep","text":"Dongchen Zhang","code":""},{"path":"/reference/MODIS_LAI_prep.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare MODIS LAI data for the SDA workflow. — MODIS_LAI_prep","title":"Prepare MODIS LAI data for the SDA workflow. — MODIS_LAI_prep","text":"Prepare MODIS LAI data SDA workflow.","code":""},{"path":"/reference/MODIS_LAI_prep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare MODIS LAI data for the SDA workflow. — MODIS_LAI_prep","text":"","code":"MODIS_LAI_prep(   site_info,   time_points,   outdir = NULL,   search_window = 30,   export_csv = FALSE,   sd_threshold = 20,   skip_download = FALSE,   boundary = NULL )"},{"path":"/reference/MODIS_LAI_prep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare MODIS LAI data for the SDA workflow. — MODIS_LAI_prep","text":"site_info list: Bety list site info including site_id, lon, lat. time_points character: vector contains time point within start end date. outdir character: final CSV file stored. search_window numeric: search window locate available LAI values. export_csv boolean: decide want export CSV file. sd_threshold numeric character: filtering estimations unrealistic high standard error, default 20. QC check skipped set NULL. skip_download boolean: determine want use existing LAI.csv file skip MODIS LAI download part. boundary numeric vector list: upper lower quantiles filtering noisy LAI values (e.g., c(0.05, 0.95) list(0.05, 0.95)). default NULL.","code":""},{"path":"/reference/MODIS_LAI_prep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare MODIS LAI data for the SDA workflow. — MODIS_LAI_prep","text":"data frame containing LAI sd site time step.","code":""},{"path":"/reference/MODIS_LAI_prep.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prepare MODIS LAI data for the SDA workflow. — MODIS_LAI_prep","text":"Dongchen Zhang","code":""},{"path":"/reference/MODIS_LAI_ts_filter.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare MODIS LAI data from the NASA DAAC server for the SDA workflow. — MODIS_LAI_ts_filter","title":"Prepare MODIS LAI data from the NASA DAAC server for the SDA workflow. — MODIS_LAI_ts_filter","text":"Prepare MODIS LAI data NASA DAAC server SDA workflow.","code":""},{"path":"/reference/MODIS_LAI_ts_filter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare MODIS LAI data from the NASA DAAC server for the SDA workflow. — MODIS_LAI_ts_filter","text":"","code":"MODIS_LAI_ts_filter(lai.csv, boundary = c(0.05, 0.95))"},{"path":"/reference/MODIS_LAI_ts_filter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare MODIS LAI data from the NASA DAAC server for the SDA workflow. — MODIS_LAI_ts_filter","text":"lai.csv data frame: data frame containing date, site id, lat, lon, lai, sd, qc columns. boundary numeric: vector contains upper lower quantiles filtering lai records. default c(0.05, 0.95).","code":""},{"path":"/reference/MODIS_LAI_ts_filter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare MODIS LAI data from the NASA DAAC server for the SDA workflow. — MODIS_LAI_ts_filter","text":"data frame containing date, site id, lat, lon, lai, sd, qc columns.","code":""},{"path":"/reference/MODIS_LAI_ts_filter.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prepare MODIS LAI data from the NASA DAAC server for the SDA workflow. — MODIS_LAI_ts_filter","text":"Dongchen Zhang","code":""},{"path":"/reference/MODIS_LC_prep.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare MODIS land cover data for the SDA workflow. — MODIS_LC_prep","title":"Prepare MODIS land cover data for the SDA workflow. — MODIS_LC_prep","text":"Prepare MODIS land cover data SDA workflow.","code":""},{"path":"/reference/MODIS_LC_prep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare MODIS land cover data for the SDA workflow. — MODIS_LC_prep","text":"","code":"MODIS_LC_prep(   site_info,   time_points,   outdir = NULL,   qc.filter = c(\"000\", \"001\") )"},{"path":"/reference/MODIS_LC_prep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare MODIS land cover data for the SDA workflow. — MODIS_LC_prep","text":"site_info Bety list site info including site_id, lon, lat. time_points vector contains time point within start end date. outdir final CSV file stored. qc.filter values pass QC check. check skipped NULL.","code":""},{"path":"/reference/MODIS_LC_prep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare MODIS land cover data for the SDA workflow. — MODIS_LC_prep","text":"data frame containing MODIS land cover types site time step.","code":""},{"path":"/reference/MODIS_LC_prep.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prepare MODIS land cover data for the SDA workflow. — MODIS_LC_prep","text":"function enables feature grabbing pre-extracted MODIS LC CSV files site records skipped (See Line 33). detail, loading previous `LC.csv` file, contains previous extracted land cover records trying match current requests (location, time). requests fail match regarded new extractions combine previous `LC.csv` file.","code":""},{"path":"/reference/MODIS_LC_prep.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prepare MODIS land cover data for the SDA workflow. — MODIS_LC_prep","text":"Dongchen Zhang","code":""},{"path":"/reference/NASA_CMR_finder.html","id":null,"dir":"Reference","previous_headings":"","what":"Create URL that can be used to request data from NASA DAAC server. — NASA_CMR_finder","title":"Create URL that can be used to request data from NASA DAAC server. — NASA_CMR_finder","text":"Create URL can used request data NASA DAAC server.","code":""},{"path":"/reference/NASA_CMR_finder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create URL that can be used to request data from NASA DAAC server. — NASA_CMR_finder","text":"","code":"NASA_CMR_finder(doi)"},{"path":"/reference/NASA_CMR_finder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create URL that can be used to request data from NASA DAAC server. — NASA_CMR_finder","text":"doi Character: data DOI NASA DAAC server, can obtained directly NASA ORNL DAAC data portal (e.g., GEDI L4A https://daac.ornl.gov/cgi-bin/dsviewer.pl?ds_id=2056).","code":""},{"path":"/reference/NASA_CMR_finder.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create URL that can be used to request data from NASA DAAC server. — NASA_CMR_finder","text":"list containing corresponding provider concept ids given data doi.","code":""},{"path":"/reference/NASA_CMR_finder.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create URL that can be used to request data from NASA DAAC server. — NASA_CMR_finder","text":"Dongchen Zhang","code":""},{"path":"/reference/NASA_CMR_finder.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create URL that can be used to request data from NASA DAAC server. — NASA_CMR_finder","text":"","code":"if (FALSE) { # \\dontrun{ provider_conceptID <- NASA_CMR_finder(\"10.3334/ORNLDAAC/2183\") } # }"},{"path":"/reference/NASA_DAAC_URL.html","id":null,"dir":"Reference","previous_headings":"","what":"Create URL that can be used to request data from NASA DAAC server. — NASA_DAAC_URL","title":"Create URL that can be used to request data from NASA DAAC server. — NASA_DAAC_URL","text":"Create URL can used request data NASA DAAC server.","code":""},{"path":"/reference/NASA_DAAC_URL.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create URL that can be used to request data from NASA DAAC server. — NASA_DAAC_URL","text":"","code":"NASA_DAAC_URL(   base_url = \"https://cmr.earthdata.nasa.gov/search/granules.json?pretty=true\",   provider,   page_size = 2000,   page = 1,   concept_id,   bbox,   daterange = NULL )"},{"path":"/reference/NASA_DAAC_URL.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create URL that can be used to request data from NASA DAAC server. — NASA_DAAC_URL","text":"base_url Character: base URL CMR search. default \"https://cmr.earthdata.nasa.gov/search/granules.json?pretty=true\". provider Character: ID data provider NASA DAAC. See `NASA_CMR_finder` details. page_size Numeric: maximum requested length, default 2000. page Numeric: page URL, default 1. concept_id Character: CMR Concept ID. See `NASA_CMR_finder` details. bbox Numeric: vector bounding box coordinates. daterange Character: vectors requested start end dates. form \"yyyy-mm-dd\".","code":""},{"path":"/reference/NASA_DAAC_URL.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create URL that can be used to request data from NASA DAAC server. — NASA_DAAC_URL","text":"character URL can used request data.","code":""},{"path":"/reference/NASA_DAAC_URL.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create URL that can be used to request data from NASA DAAC server. — NASA_DAAC_URL","text":"Dongchen Zhang","code":""},{"path":"/reference/NASA_DAAC_URL.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create URL that can be used to request data from NASA DAAC server. — NASA_DAAC_URL","text":"","code":"if (FALSE) { # \\dontrun{ provider <- \"ORNL_CLOUD\" concept_id <- \"C2770099044-ORNL_CLOUD\" bbox <- \"-121,33,-117,35\" daterange <- c(\"2022-02-23\", \"2022-05-30\") URL <- NASA_DAAC_URL(provider = provider,  concept_id = concept_id,  bbox = bbox,  daterange = daterange) } # }"},{"path":"/reference/NASA_DAAC_download.html","id":null,"dir":"Reference","previous_headings":"","what":"Parallel download data from the NASA ORNL DAAC server given period, spatial bounding box, and data DOI. — NASA_DAAC_download","title":"Parallel download data from the NASA ORNL DAAC server given period, spatial bounding box, and data DOI. — NASA_DAAC_download","text":"Parallel download data NASA ORNL DAAC server given period, spatial bounding box, data DOI.","code":""},{"path":"/reference/NASA_DAAC_download.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parallel download data from the NASA ORNL DAAC server given period, spatial bounding box, and data DOI. — NASA_DAAC_download","text":"","code":"NASA_DAAC_download(   ul_lat,   ul_lon,   lr_lat,   lr_lon,   ncore = 1,   from,   to,   outdir = getwd(),   band = NULL,   data_version = NULL,   credential_path = NULL,   doi,   just_path = FALSE )"},{"path":"/reference/NASA_DAAC_download.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parallel download data from the NASA ORNL DAAC server given period, spatial bounding box, and data DOI. — NASA_DAAC_download","text":"ul_lat Numeric: upper left latitude. ul_lon Numeric: upper left longitude. lr_lat Numeric: lower right latitude. lr_lon Numeric: lower right longitude. ncore Numeric: numbers core used maximum core Character: date data search starts. form \"yyyy-mm-dd\". Character: date data search end. form \"yyyy-mm-dd\". outdir Character: path directory save downloaded files. Default current work directory(getwd()). band Character: band name (vector band names) data requested. Default NULL. data_version Character: version (typically starts V) data requested. Default NULL. credential_path Character: physical path credential file (.netrc file). default NULL. doi Character: data DOI NASA DAAC server, can obtained directly NASA ORNL DAAC data portal (e.g., GEDI L4A https://daac.ornl.gov/cgi-bin/dsviewer.pl?ds_id=2056). just_path Boolean: just want metadata URL proceed actual download.","code":""},{"path":"/reference/NASA_DAAC_download.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parallel download data from the NASA ORNL DAAC server given period, spatial bounding box, and data DOI. — NASA_DAAC_download","text":"Physical paths downloaded files (just_path = T) URLs files (just_path = F).","code":""},{"path":"/reference/NASA_DAAC_download.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Parallel download data from the NASA ORNL DAAC server given period, spatial bounding box, and data DOI. — NASA_DAAC_download","text":"Dongchen Zhang","code":""},{"path":"/reference/NASA_DAAC_download.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parallel download data from the NASA ORNL DAAC server given period, spatial bounding box, and data DOI. — NASA_DAAC_download","text":"","code":"if (FALSE) { # \\dontrun{ # SHIFT Hyper-spectral data. ul_lat <- 35 ul_lon <- -121 lr_lat <- 33 lr_lon <- -117 from <- \"2022-02-23\" to <- \"2022-05-30\" doi <- \"10.3334/ORNLDAAC/2183\" paths <- NASA_DAAC_download(ul_lat = ul_lat,                              ul_lon = ul_lon,                              lr_lat = lr_lat,                              lr_lon = lr_lon,                              from = from,                              to = to,                              doi = doi,                             just_path = T) # GEDI level 4A data. ul_lat <- 85 ul_lon <- -179 lr_lat <- 7 lr_lon <- -20 from <- \"2020-01-01\" to <- \"2020-12-31\" doi <- \"10.3334/ORNLDAAC/2056\" paths <- NASA_DAAC_download(ul_lat = ul_lat,                              ul_lon = ul_lon,                              lr_lat = lr_lat,                              lr_lon = lr_lon,                              from = from,                              to = to,                             data_version = \"V2_1\",                              doi = doi,                             just_path = T) # MODIS LAI data. ul_lat <- 85 ul_lon <- -179 lr_lat <- 7 lr_lon <- -20 from <- \"2020-01-01\" to <- \"2020-01-31\" doi <- \"10.5067/MODIS/MCD15A3H.061\" paths <- NASA_DAAC_download(ul_lat = ul_lat,                              ul_lon = ul_lon,                              lr_lat = lr_lat,                              lr_lon = lr_lon,                              from = from,                              to = to,                              doi = doi,                             just_path = T) # SMAP Soil Moisture data. ul_lat <- 85 ul_lon <- -179 lr_lat <- 7 lr_lon <- -20 from <- \"2020-01-01\" to <- \"2020-01-31\" doi <- \"10.5067/02LGW4DGJYRX\" paths <- NASA_DAAC_download(ul_lat = ul_lat,                              ul_lon = ul_lon,                              lr_lat = lr_lat,                              lr_lon = lr_lon,                              from = from,                              to = to,                              doi = doi,                             just_path = T) # GLANCE Phenology and LC data. ul_lat <- 85 ul_lon <- -179 lr_lat <- 7 lr_lon <- -20 from <- \"2019-01-01\" to <- \"2019-12-31\" doi <- \"10.5067/MEaSUREs/GLanCE/GLanCE30.001\" paths <- NASA_DAAC_download(ul_lat = ul_lat,                              ul_lon = ul_lon,                              lr_lat = lr_lat,                              lr_lon = lr_lon,                              from = from,                              to = to,                              doi = doi,                             just_path = T) # HLS reflectance data. ul_lat <- 35 ul_lon <- -121 lr_lat <- 33 lr_lon <- -117 from <- \"2022-02-23\" to <- \"2022-05-30\" doi <- \"10.5067/HLS/HLSS30.002\" paths <- NASA_DAAC_download(ul_lat = ul_lat,                              ul_lon = ul_lon,                              lr_lat = lr_lat,                              lr_lon = lr_lon,                              from = from,                              to = to,                              doi = doi,                             just_path = T)                             ul_lat <- 35 # HLS Phenology data. ul_lon <- -121 lr_lat <- 33 lr_lon <- -117 from <- \"2019-01-01\" to <- \"2019-12-31\" doi <- \"10.5067/Community/MuSLI/MSLSP30NA.011\" paths <- NASA_DAAC_download(ul_lat = ul_lat,                             ul_lon = ul_lon,                             lr_lat = lr_lat,                             lr_lon = lr_lon,                             from = from,                             to = to,                             doi = doi,                             just_path = T) } # }"},{"path":"/reference/Prep.MODIS.CSV.from.DAAC.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare MODIS LAI data from the NASA DAAC server for the SDA workflow. — Prep.MODIS.CSV.from.DAAC","title":"Prepare MODIS LAI data from the NASA DAAC server for the SDA workflow. — Prep.MODIS.CSV.from.DAAC","text":"Prepare MODIS LAI data NASA DAAC server SDA workflow.","code":""},{"path":"/reference/Prep.MODIS.CSV.from.DAAC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare MODIS LAI data from the NASA DAAC server for the SDA workflow. — Prep.MODIS.CSV.from.DAAC","text":"","code":"Prep.MODIS.CSV.from.DAAC(   site_info,   extent,   from,   to,   download.outdir,   csv.outdir,   credential_path )"},{"path":"/reference/Prep.MODIS.CSV.from.DAAC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare MODIS LAI data from the NASA DAAC server for the SDA workflow. — Prep.MODIS.CSV.from.DAAC","text":"site_info list: Bety list site info including site_id, lon, lat. extent numeric: vector contains bounding box covers sites (West longitude, East longitude, South latitude ,North latitude). character: start time searching MODIS products. character: end time searching MODIS products. download.outdir character: MODIS tiles stored. csv.outdir character: final CSV file stored. credential_path Character: physical path credential file (.netrc file).","code":""},{"path":"/reference/Prep.MODIS.CSV.from.DAAC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare MODIS LAI data from the NASA DAAC server for the SDA workflow. — Prep.MODIS.CSV.from.DAAC","text":"data frame containing LAI sd site time step.","code":""},{"path":"/reference/Prep.MODIS.CSV.from.DAAC.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prepare MODIS LAI data from the NASA DAAC server for the SDA workflow. — Prep.MODIS.CSV.from.DAAC","text":"Dongchen Zhang","code":""},{"path":"/reference/Prep.SMAP.CSV.from.DAAC.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare SMAP soil moisture profile (SMP) data from the NASA DAAC server for the SDA workflow. The CSV file that works for the `SMAP_SMP_prep` function will be exported. — Prep.SMAP.CSV.from.DAAC","title":"Prepare SMAP soil moisture profile (SMP) data from the NASA DAAC server for the SDA workflow. The CSV file that works for the `SMAP_SMP_prep` function will be exported. — Prep.SMAP.CSV.from.DAAC","text":"Prepare SMAP soil moisture profile (SMP) data NASA DAAC server SDA workflow. CSV file works `SMAP_SMP_prep` function exported.","code":""},{"path":"/reference/Prep.SMAP.CSV.from.DAAC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare SMAP soil moisture profile (SMP) data from the NASA DAAC server for the SDA workflow. The CSV file that works for the `SMAP_SMP_prep` function will be exported. — Prep.SMAP.CSV.from.DAAC","text":"","code":"Prep.SMAP.CSV.from.DAAC(   site_info,   extent,   from,   to,   download.outdir,   csv.outdir,   credential_path )"},{"path":"/reference/Prep.SMAP.CSV.from.DAAC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare SMAP soil moisture profile (SMP) data from the NASA DAAC server for the SDA workflow. The CSV file that works for the `SMAP_SMP_prep` function will be exported. — Prep.SMAP.CSV.from.DAAC","text":"site_info list: Bety list site info including site_id, lon, lat. extent numeric: vector contains bounding box covers sites (West longitude, East longitude, South latitude ,North latitude). character: start time searching MODIS products. character: end time searching MODIS products. download.outdir character: MODIS tiles stored. csv.outdir character: final CSV file stored. credential_path Character: physical path credential file (.netrc file).","code":""},{"path":"/reference/Prep.SMAP.CSV.from.DAAC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare SMAP soil moisture profile (SMP) data from the NASA DAAC server for the SDA workflow. The CSV file that works for the `SMAP_SMP_prep` function will be exported. — Prep.SMAP.CSV.from.DAAC","text":"data frame containing SMP sd site time step.","code":""},{"path":"/reference/Prep.SMAP.CSV.from.DAAC.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prepare SMAP soil moisture profile (SMP) data from the NASA DAAC server for the SDA workflow. The CSV file that works for the `SMAP_SMP_prep` function will be exported. — Prep.SMAP.CSV.from.DAAC","text":"Dongchen Zhang","code":""},{"path":"/reference/Prep_AGB_IC_from_2010_global.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract ensemble above ground biomass density from pre-existing GeoTIFF files for the SDA workflow. Note that, this function only works for those products who have both mean and uncertainty GeoTIFF images prepared. And it works under the 2010 Global AGB products: DOI: https://doi.org/10.3334/ORNLDAAC/1763. — Prep_AGB_IC_from_2010_global","title":"Extract ensemble above ground biomass density from pre-existing GeoTIFF files for the SDA workflow. Note that, this function only works for those products who have both mean and uncertainty GeoTIFF images prepared. And it works under the 2010 Global AGB products: DOI: https://doi.org/10.3334/ORNLDAAC/1763. — Prep_AGB_IC_from_2010_global","text":"Extract ensemble ground biomass density pre-existing GeoTIFF files SDA workflow. Note , function works products mean uncertainty GeoTIFF images prepared. works 2010 Global AGB products: DOI: https://doi.org/10.3334/ORNLDAAC/1763.","code":""},{"path":"/reference/Prep_AGB_IC_from_2010_global.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract ensemble above ground biomass density from pre-existing GeoTIFF files for the SDA workflow. Note that, this function only works for those products who have both mean and uncertainty GeoTIFF images prepared. And it works under the 2010 Global AGB products: DOI: https://doi.org/10.3334/ORNLDAAC/1763. — Prep_AGB_IC_from_2010_global","text":"","code":"Prep_AGB_IC_from_2010_global(site_info, paths.list, ens)"},{"path":"/reference/Prep_AGB_IC_from_2010_global.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract ensemble above ground biomass density from pre-existing GeoTIFF files for the SDA workflow. Note that, this function only works for those products who have both mean and uncertainty GeoTIFF images prepared. And it works under the 2010 Global AGB products: DOI: https://doi.org/10.3334/ORNLDAAC/1763. — Prep_AGB_IC_from_2010_global","text":"site_info Bety list site info including site_id, lon, lat. paths.list list containing file paths `mean` `uncertainty` datasets. ens ensemble number.","code":""},{"path":"/reference/Prep_AGB_IC_from_2010_global.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract ensemble above ground biomass density from pre-existing GeoTIFF files for the SDA workflow. Note that, this function only works for those products who have both mean and uncertainty GeoTIFF images prepared. And it works under the 2010 Global AGB products: DOI: https://doi.org/10.3334/ORNLDAAC/1763. — Prep_AGB_IC_from_2010_global","text":"data frame containing sampled ground biomass densities, column represent site.","code":""},{"path":"/reference/Prep_AGB_IC_from_2010_global.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract ensemble above ground biomass density from pre-existing GeoTIFF files for the SDA workflow. Note that, this function only works for those products who have both mean and uncertainty GeoTIFF images prepared. And it works under the 2010 Global AGB products: DOI: https://doi.org/10.3334/ORNLDAAC/1763. — Prep_AGB_IC_from_2010_global","text":"Dongchen Zhang","code":""},{"path":"/reference/SMAP_SMP_prep.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare SMAP Soil Moisture (SMP) data for the SDA workflow. — SMAP_SMP_prep","title":"Prepare SMAP Soil Moisture (SMP) data for the SDA workflow. — SMAP_SMP_prep","text":"Prepare SMAP Soil Moisture (SMP) data SDA workflow.","code":""},{"path":"/reference/SMAP_SMP_prep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare SMAP Soil Moisture (SMP) data for the SDA workflow. — SMAP_SMP_prep","text":"","code":"SMAP_SMP_prep(   site_info,   start_date,   end_date,   time_points,   outdir,   search_window = 30,   export_csv = TRUE,   update_csv = FALSE )"},{"path":"/reference/SMAP_SMP_prep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare SMAP Soil Moisture (SMP) data for the SDA workflow. — SMAP_SMP_prep","text":"site_info Bety list site info including site_id, lon, lat. start_date Start date SDA workflow. end_date End date SDA workflow. time_points vector contains time point within start end date. outdir final CSV file, CSV file GEE stored. search_window search window locate available SMP values. export_csv Decide want export CSV file. update_csv Decide want update current CSV file given updated SMAP_gee.csv file","code":""},{"path":"/reference/SMAP_SMP_prep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare SMAP Soil Moisture (SMP) data for the SDA workflow. — SMAP_SMP_prep","text":"data frame containing SMAP smp sd site time step.","code":""},{"path":"/reference/SMAP_SMP_prep.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prepare SMAP Soil Moisture (SMP) data for the SDA workflow. — SMAP_SMP_prep","text":"Dongchen Zhang","code":""},{"path":"/reference/call_MODIS.html","id":null,"dir":"Reference","previous_headings":"","what":"call_MODIS — call_MODIS","title":"call_MODIS — call_MODIS","text":"Get MODIS data date location","code":""},{"path":"/reference/call_MODIS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"call_MODIS — call_MODIS","text":"","code":"call_MODIS(   var,   product,   band,   site_info,   product_dates,   outdir = NULL,   run_parallel = FALSE,   ncores = NULL,   package_method = \"MODISTools\",   QC_filter = FALSE,   progress = FALSE )"},{"path":"/reference/call_MODIS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"call_MODIS — call_MODIS","text":"var simple name modis dataset variable (e.g. lai) product string value MODIS product number band string value measurement extract site_info Bety list site info parsing MODIS data: list(site_id, site_name, lat, lon, time_zone) product_dates character vector start end date data YYYYJJJ outdir output file stored. Default NULL case values returned. path provided values returned written disk. run_parallel optional method download data paralleize. works 1 site needed >1 CPUs available. ncores number cpus use run_parallel set TRUE. know number CPU's available, enter NULL. package_method string value inform function package method use download modis data. Either \"MODISTools\" \"reticulate\" (optional) QC_filter Converts QC values band keeps data values excellent good (described MODIS documentation), removes bad values. qc_band must supplied parameter work. Default False. MODISTools option. progress TRUE reports download progress bar dataset, FALSE omits download progress bar. Default TRUE. MODISTools option. Requires Python3 reticulate method option. number required python libraries. sudo -H pip install numpy suds netCDF4 json depends MODISTools package version 1.1.0","code":""},{"path":"/reference/call_MODIS.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"call_MODIS — call_MODIS","text":"Bailey Morrison","code":""},{"path":"/reference/call_MODIS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"call_MODIS — call_MODIS","text":"","code":"if (FALSE) { # \\dontrun{ site_info <- list(   site_id = 1,   site_name = \"test\",   lat = 44,   lon = 90,   time_zone = \"UTC\") test_modistools <- call_MODIS(   var = \"lai\",   product = \"MOD15A2H\",   band = \"Lai_500m\",   site_info = site_info,   product_dates = c(\"2001150\", \"2001365\"),   outdir = NULL,   run_parallel = TRUE,   ncores = NULL,   package_method = \"MODISTools\",   QC_filter = TRUE,   progress = FALSE) } # }"},{"path":"/reference/construct_remotedata_filename.html","id":null,"dir":"Reference","previous_headings":"","what":"construct_remotedata_filename — construct_remotedata_filename","title":"construct_remotedata_filename — construct_remotedata_filename","text":"construct remotedata module file names","code":""},{"path":"/reference/construct_remotedata_filename.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"construct_remotedata_filename — construct_remotedata_filename","text":"","code":"construct_remotedata_filename(   source,   collection,   siteid,   scale = NULL,   projection = NULL,   qc = NULL,   algorithm = NULL,   out_process_data = NULL )"},{"path":"/reference/construct_remotedata_filename.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"construct_remotedata_filename — construct_remotedata_filename","text":"source source collection collection product requested source siteid shortform siteid scale scale, NULL default projection projection, NULL default qc qc_parameter, NULL default algorithm algorithm name process data, NULL default out_process_data variable name requested processed file, NULL default","code":""},{"path":"/reference/construct_remotedata_filename.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"construct_remotedata_filename — construct_remotedata_filename","text":"remotedata_file_names","code":""},{"path":"/reference/construct_remotedata_filename.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"construct_remotedata_filename — construct_remotedata_filename","text":"Ayush Prasad","code":""},{"path":[]},{"path":"/reference/download.LandTrendr.AGB.html","id":null,"dir":"Reference","previous_headings":"","what":"download.LandTrendr.AGB — download.LandTrendr.AGB","title":"download.LandTrendr.AGB — download.LandTrendr.AGB","text":"download.LandTrendr.AGB","code":""},{"path":"/reference/download.LandTrendr.AGB.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"download.LandTrendr.AGB — download.LandTrendr.AGB","text":"","code":"download.LandTrendr.AGB(   outdir,   target_dataset = \"biomass\",   product_dates = NULL,   product_version = \"v1\",   con = NULL,   run_parallel = TRUE,   ncores = NULL,   overwrite = FALSE )"},{"path":"/reference/download.LandTrendr.AGB.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"download.LandTrendr.AGB — download.LandTrendr.AGB","text":"outdir place output target_dataset LandTrendr dataset download?  Default = \"biomass\" product_dates data product dates download product_version Optional. LandTrend AGB provided two versions, v0 v1 (latest version) con Optional database connection. specified code check see run_parallel Logical. Download extract files parallel? ncores Optional. run_parallel=TRUE many cores use?  left NULL select max number -1 overwrite Logical. Overwrite existing files replace new versions","code":""},{"path":"/reference/download.LandTrendr.AGB.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"download.LandTrendr.AGB — download.LandTrendr.AGB","text":"data.frame summarize results function call","code":""},{"path":"/reference/download.LandTrendr.AGB.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"download.LandTrendr.AGB — download.LandTrendr.AGB","text":"Shawn Serbin","code":""},{"path":"/reference/download.LandTrendr.AGB.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"download.LandTrendr.AGB — download.LandTrendr.AGB","text":"","code":"if (FALSE) { # \\dontrun{ outdir <- \"~/scratch/abg_data/\" product_dates <- c(1990, 1991, 1995)  # using discontinous, or specific years product_dates2 <- seq(1992, 1995, 1)  # using a date sequence for selection of years product_version = \"v1\"  results <- PEcAn.data.remote::download.LandTrendr.AGB(outdir=outdir,             product_dates = product_dates,             product_version = product_version)  results <- PEcAn.data.remote::download.LandTrendr.AGB(outdir=outdir,             product_dates = product_dates2,             product_version = product_version) } # }"},{"path":"/reference/download.NLCD.html","id":null,"dir":"Reference","previous_headings":"","what":"download.NLCD — download.NLCD","title":"download.NLCD — download.NLCD","text":"Downloads unzips National Land Cover Database http://www.mrlc.gov/nlcd2011.php. automatically insert PEcAn database database connection provided.","code":""},{"path":"/reference/download.NLCD.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"download.NLCD — download.NLCD","text":"","code":"download.NLCD(outdir, year = 2011, con = NULL)"},{"path":"/reference/download.NLCD.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"download.NLCD — download.NLCD","text":"outdir Directory download NLCD year NLCD year download. 2001 2011 currently supported. con Optional database connection. specified code check see file already exists PEcAn downloading, also create database entry new downloads","code":""},{"path":"/reference/download.NLCD.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"download.NLCD — download.NLCD","text":"Mike Dietze","code":""},{"path":"/reference/download_thredds.html","id":null,"dir":"Reference","previous_headings":"","what":"download.thredds — download_thredds","title":"download.thredds — download_thredds","text":"download.thredds","code":""},{"path":"/reference/download_thredds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"download.thredds — download_thredds","text":"","code":"download_thredds(   site_info,   dates,   varid,   dir_url,   data_url,   run_parallel = FALSE,   outdir = NULL )"},{"path":"/reference/download_thredds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"download.thredds — download_thredds","text":"site_info list containing site_id, site_name, lat, lon, time_zone. Derived BETY using PEcAn .xml settings file site information. Can use get_site_info function generate list. dates vector start end date dataset YYYYmmdd, YYYY-mm-dd, YYYYjjj, date object. varid character vector shorthand variable name. .e. LAI dir_url catalog url data ncei.noaa.gov/thredds website data_url opendap url data ncei.noaa.gov/thredds website run_parallel Logical. Download extract files parallel? outdir file location place output","code":""},{"path":"/reference/download_thredds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"download.thredds — download_thredds","text":"data.frame summarize results function call","code":""},{"path":"/reference/download_thredds.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"download.thredds — download_thredds","text":"Bailey Morrison","code":""},{"path":"/reference/download_thredds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"download.thredds — download_thredds","text":"","code":"if (FALSE) { # \\dontrun{ results <- download_thredds(   site_info = site_info,   dates = c(\"19950201\", \"19961215\"),   varid = \"LAI\",   dir_url = \"https://www.ncei.noaa.gov/thredds/catalog/cdr/lai/files\",   data_url = \"https://www.ncei.noaa.gov/thredds/dodsC/cdr/lai/files\",   run_parallel = TRUE,   outdir = NULL) } # }"},{"path":"/reference/extract.LandTrendr.AGB.html","id":null,"dir":"Reference","previous_headings":"","what":"extract.LandTrendr.AGB — extract.LandTrendr.AGB","title":"extract.LandTrendr.AGB — extract.LandTrendr.AGB","text":"extract.LandTrendr.AGB","code":""},{"path":"/reference/extract.LandTrendr.AGB.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"extract.LandTrendr.AGB — extract.LandTrendr.AGB","text":"","code":"extract.LandTrendr.AGB(   site_info,   dataset = \"median\",   buffer = NULL,   fun = \"mean\",   data_dir = NULL,   product_dates = NULL,   output_file = NULL,   ... )"},{"path":"/reference/extract.LandTrendr.AGB.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"extract.LandTrendr.AGB — extract.LandTrendr.AGB","text":"site_info list site info parsing AGB data: list(site_id, site_name, lat, lon, time_zone) dataset LandTrendr dataset parse, \"median\" \"stdv\".Default: \"median\" buffer Optional. operate desired buffer area (yet implemented) fun Optional function apply buffer area.  Default - mean data_dir directory input data located. Can NUL con specified product_dates Process extract data selected years. Default behavior (product_dates = NULL) extract data availible years BETYdb data_dir output_file Path save LandTrendr_AGB_output.RData file containing output extraction list (see return) ... Additional arguments, currently ignored","code":""},{"path":"/reference/extract.LandTrendr.AGB.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"extract.LandTrendr.AGB — extract.LandTrendr.AGB","text":"list two containing median AGB values per pixel corresponding standard deviation values (uncertainties)","code":""},{"path":"/reference/extract.LandTrendr.AGB.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"extract.LandTrendr.AGB — extract.LandTrendr.AGB","text":"Shawn Serbin, Alexey Shiklomanov","code":""},{"path":"/reference/extract.LandTrendr.AGB.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"extract.LandTrendr.AGB — extract.LandTrendr.AGB","text":"","code":"if (FALSE) { # \\dontrun{  # Example 1 - using BETYdb site IDs to extract data # Database connection (optional)  con <- PEcAn.DB::db.open(   list(user='bety', password='bety', host='localhost',   dbname='bety', driver='PostgreSQL',write=TRUE))  site_ID <- c(2000000023,1000025731,676,1000005149) # BETYdb site IDs suppressWarnings(site_qry <- glue::glue_sql(\"SELECT *, ST_X(ST_CENTROID(geometry)) AS lon,  ST_Y(ST_CENTROID(geometry)) AS lat FROM sites WHERE id IN ({ids*})\",  ids = site_ID, .con = con)) suppressWarnings(qry_results <- DBI::dbSendQuery(con,site_qry)) suppressWarnings(qry_results <- DBI::dbFetch(qry_results)) site_info <- list(site_id=qry_results$id, site_name=qry_results$sitename, lat=qry_results$lat,  lon=qry_results$lon, time_zone=qry_results$time_zone) data_dir <- \"~/scratch/agb_data/\"  results <- extract.LandTrendr.AGB(site_info, \"median\", buffer = NULL, fun = \"mean\",  data_dir, product_dates, output_file)  } # }"},{"path":"/reference/extract_NLCD.html","id":null,"dir":"Reference","previous_headings":"","what":"extract.NLCD — extract_NLCD","title":"extract.NLCD — extract_NLCD","text":"Based codes Christy Rollinson Max Joseph (http://mbjoseph.github.io/2014/11/08/nlcd.html)","code":""},{"path":"/reference/extract_NLCD.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"extract.NLCD — extract_NLCD","text":"","code":"extract_NLCD(buffer, coords, data_dir = NULL, con = NULL, year = 2011)"},{"path":"/reference/extract_NLCD.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"extract.NLCD — extract_NLCD","text":"buffer search radius (meters) coords data frame containing elements 'long' 'lat'. Currently just supports single point extraction. data_dir directory input data located. Can NUL con specified con connection PEcAn database. Can NULL data_dir specified year NLCD year extract. data_dir provided, must one `2001` `2011`","code":""},{"path":"/reference/extract_NLCD.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"extract.NLCD — extract_NLCD","text":"dataframe fractional cover different cover classes","code":""},{"path":"/reference/extract_NLCD.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"extract.NLCD — extract_NLCD","text":"Mike Dietze","code":""},{"path":"/reference/extract_phenology_MODIS.html","id":null,"dir":"Reference","previous_headings":"","what":"Get MODIS phenology data by date and location — extract_phenology_MODIS","title":"Get MODIS phenology data by date and location — extract_phenology_MODIS","text":"Get MODIS phenology data date location","code":""},{"path":"/reference/extract_phenology_MODIS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get MODIS phenology data by date and location — extract_phenology_MODIS","text":"","code":"extract_phenology_MODIS(   site_info,   start_date,   end_date,   outdir,   run_parallel = TRUE,   ncores = NULL )"},{"path":"/reference/extract_phenology_MODIS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get MODIS phenology data by date and location — extract_phenology_MODIS","text":"site_info dataframe site info containing BETYdb site ID, site name, latitude, longitude, e.g. start_date Start date download data end_date End date download data outdir Path store outputs run_parallel optional method download data parallely. works 1 site needed >1 CPUs available. ncores number cpus use run_parallel set TRUE. know number CPU's available, enter NULL.","code":""},{"path":"/reference/extract_phenology_MODIS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get MODIS phenology data by date and location — extract_phenology_MODIS","text":"path output file output file saved CSV file outdir. Output column names \"year\", \"site_id\", \"lat\", \"lon\", \"leafonday\",\"leafoffday\",\"leafon_qa\",\"leafoff_qa\"","code":""},{"path":"/reference/extract_phenology_MODIS.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get MODIS phenology data by date and location — extract_phenology_MODIS","text":"Qianyu Li","code":""},{"path":"/reference/extract_thredds_nc.html","id":null,"dir":"Reference","previous_headings":"","what":"extract_thredds_nc — extract_thredds_nc","title":"extract_thredds_nc — extract_thredds_nc","text":"extract_thredds_nc","code":""},{"path":"/reference/extract_thredds_nc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"extract_thredds_nc — extract_thredds_nc","text":"","code":"extract_thredds_nc(site_info, url, varid)"},{"path":"/reference/extract_thredds_nc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"extract_thredds_nc — extract_thredds_nc","text":"site_info list containing site_id, site_name, lat, lon, time_zone. Derived BETY using PEcAn .xml settings file site information. Can use get_site_info function generate list. url THREDDS url .nc file extract data . varid character vector shorthand variable name. .e. LAI","code":""},{"path":"/reference/extract_thredds_nc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"extract_thredds_nc — extract_thredds_nc","text":"dataframe values date/site combination  THREDDS file","code":""},{"path":"/reference/extract_thredds_nc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"extract_thredds_nc — extract_thredds_nc","text":"Bailey Morrison","code":""},{"path":"/reference/extract_thredds_nc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"extract_thredds_nc — extract_thredds_nc","text":"","code":"if (FALSE) { # \\dontrun{ thredds_url = paste0( # breaking up long URL for readability   \"https://www.ncei.noaa.gov/thredds/dodsC/cdr/lai/files/1995/\",   \"AVHRR-Land_v005_AVH15C1_NOAA-14_19950201_c20180831220722.nc\") output <- extract_thredds_nc(   site_info = site_info,   url = thredds_url,   varid = \"LAI\") } # }"},{"path":"/reference/gdal_conversion.html","id":null,"dir":"Reference","previous_headings":"","what":"gdal_conversion — gdal_conversion","title":"gdal_conversion — gdal_conversion","text":"function provides tool remote sensing image conversion using GDAL utility.","code":""},{"path":"/reference/gdal_conversion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"gdal_conversion — gdal_conversion","text":"","code":"gdal_conversion(   in_path,   outfolder = NULL,   band_name = NULL,   tile_id = NULL,   just_band_name = TRUE,   target_format = \".tif\" )"},{"path":"/reference/gdal_conversion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"gdal_conversion — gdal_conversion","text":"in_path character: physical path image file. outfolder character: physical path folder want export converted image. Default NULL. band_name character: band name image. Default NULL. tile_id character/numeric: id differentiate different converted image tiles. just_band_name logical: just want band names image file. Default TRUE. target_format character: target image format. Default .tif.","code":""},{"path":"/reference/gdal_conversion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"gdal_conversion — gdal_conversion","text":"Please note , function supports conversions one band one image. want convert multiple images bands, make sure loop targets. Currently tested H5, NetCDF, HDF4, GeoTIFF formats. function ready GDAL supported image format.","code":""},{"path":"/reference/gdal_conversion.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"gdal_conversion — gdal_conversion","text":"Dongchen Zhang","code":""},{"path":"/reference/gdal_conversion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"gdal_conversion — gdal_conversion","text":"","code":"if (FALSE) { # \\dontrun{ in_path <- \"/projectnb/dietzelab/malmborg/CARB/HLS_data/MSLSP_10SDH_2016.nc\" outfolder <- \"/projectnb/dietzelab/dongchen/anchorSites/NA_runs/MODIS_Phenology\" band_name <- \"NumCycles\" # try grab all available bands from the target file. band_names <-    gdal_conversion(in_path = in_path,      outfolder = outfolder,      band_name = NULL,      just_band_name = T) # try convert the first band of the available band names to GeoTIFF file. f <-    gdal_conversion(in_path = in_path,      outfolder = outfolder,      band_name = band_names[1],      just_band_name = F,      target_format = \".tif\") } # }"},{"path":"/reference/gdal_translate.html","id":null,"dir":"Reference","previous_headings":"","what":"gdal_translate — gdal_translate","title":"gdal_translate — gdal_translate","text":"function provides tool gdal_translate execution.","code":""},{"path":"/reference/gdal_translate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"gdal_translate — gdal_translate","text":"","code":"gdal_translate(from, to)"},{"path":"/reference/gdal_translate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"gdal_translate — gdal_translate","text":"character: subdataset name. Generated `get_subdatasets` function. character: physical path output file.","code":""},{"path":"/reference/gdal_translate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"gdal_translate — gdal_translate","text":"Dongchen Zhang","code":""},{"path":"/reference/get_site_info.html","id":null,"dir":"Reference","previous_headings":"","what":"get_site_info — get_site_info","title":"get_site_info — get_site_info","text":"get_site_info","code":""},{"path":"/reference/get_site_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get_site_info — get_site_info","text":"","code":"get_site_info(settings)"},{"path":"/reference/get_site_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get_site_info — get_site_info","text":"settings PEcAn settings object","code":""},{"path":"/reference/get_site_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"get_site_info — get_site_info","text":"list site information derived BETY using pecan .xml  settings file site_id, site_name, lat, lon, time_zone.","code":""},{"path":"/reference/get_site_info.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"get_site_info — get_site_info","text":"Bailey Morrison","code":""},{"path":[]},{"path":"/reference/get_subdatasets.html","id":null,"dir":"Reference","previous_headings":"","what":"get_subdatasets. — get_subdatasets","title":"get_subdatasets. — get_subdatasets","text":"function provides tool reading band names remote sensing image.","code":""},{"path":"/reference/get_subdatasets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get_subdatasets. — get_subdatasets","text":"","code":"get_subdatasets(in_path)"},{"path":"/reference/get_subdatasets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get_subdatasets. — get_subdatasets","text":"in_path character: physical path image file.","code":""},{"path":"/reference/get_subdatasets.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"get_subdatasets. — get_subdatasets","text":"Dongchen Zhang","code":""},{"path":"/reference/getnetrc.html","id":null,"dir":"Reference","previous_headings":"","what":"Set NASA DAAC credentials to the .netrc file. — getnetrc","title":"Set NASA DAAC credentials to the .netrc file. — getnetrc","text":"Set NASA DAAC credentials .netrc file.","code":""},{"path":"/reference/getnetrc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set NASA DAAC credentials to the .netrc file. — getnetrc","text":"","code":"getnetrc(dl_path)"},{"path":"/reference/getnetrc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set NASA DAAC credentials to the .netrc file. — getnetrc","text":"dl_path Character: physical path .netrc credential file.","code":""},{"path":"/reference/getnetrc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Set NASA DAAC credentials to the .netrc file. — getnetrc","text":"Dongchen Zhang","code":""},{"path":"/reference/grid2netcdf.html","id":null,"dir":"Reference","previous_headings":"","what":"grid2netcdf — grid2netcdf","title":"grid2netcdf — grid2netcdf","text":"Write gridded data netcdf file","code":""},{"path":"/reference/grid2netcdf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"grid2netcdf — grid2netcdf","text":"","code":"grid2netcdf(gdata, date = \"9999-09-09\", outfile = \"out.nc\")"},{"path":"/reference/grid2netcdf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"grid2netcdf — grid2netcdf","text":"gdata gridded data write date currently ignored; date(s) `gdata` used instead outfile name generated netCDF file.","code":""},{"path":"/reference/grid2netcdf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"grid2netcdf — grid2netcdf","text":"writes netCDF file","code":""},{"path":"/reference/grid2netcdf.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"grid2netcdf — grid2netcdf","text":"David LeBauer","code":""},{"path":"/reference/merge_image_tiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge image tiles to a single image (currently support hdf and tif image format). — merge_image_tiles","title":"Merge image tiles to a single image (currently support hdf and tif image format). — merge_image_tiles","text":"Merge image tiles single image (currently support hdf tif image format).","code":""},{"path":"/reference/merge_image_tiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge image tiles to a single image (currently support hdf and tif image format). — merge_image_tiles","text":"","code":"merge_image_tiles(   in.path,   out.path = NULL,   band.name = NULL,   just.band.name = TRUE,   keep.files = FALSE,   skip.conversion = FALSE,   image.settings = list(crs = \"EPSG:4326\", dimension = NULL, ext = NULL, fun = NULL),   computation = list(GDAL_CACHEMAX = 1000, wm = \"80%\", NUM_THREADS =     parallel::detectCores() - 1, COMPRESS = \"DEFLATE\") )"},{"path":"/reference/merge_image_tiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge image tiles to a single image (currently support hdf and tif image format). — merge_image_tiles","text":".path character: physical path folder contains original image tiles. .path character: physical path folder contains converted merged images. band.name character: band name image. Default NULL. just.band.name logical: just want band names image file. Default TRUE. keep.files logical: want keep image tiles end. skip.conversion logical: want ignore image conversion. Note experimental feature, works images GeoTIFF format. image.settings list: settings used exporting merged image. image coordinate system (crs), dimension, extents (ext), average function (fun). computation list: settings used configuring computation. maximum memory per CPU (GDAL_CACHEMAX), percentage total memory (wm), number CPUs (NUM_THREADS), compress method (COMPRESS).","code":""},{"path":"/reference/merge_image_tiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge image tiles to a single image (currently support hdf and tif image format). — merge_image_tiles","text":"character: file path merged GeoTIFF file.","code":""},{"path":"/reference/merge_image_tiles.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Merge image tiles to a single image (currently support hdf and tif image format). — merge_image_tiles","text":"Please make sure image tiles stored `folder.path`. Please refer gdalwarp manual details https://gdal.org/en/stable/programs/gdalwarp.html","code":""},{"path":"/reference/merge_image_tiles.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Merge image tiles to a single image (currently support hdf and tif image format). — merge_image_tiles","text":"Dongchen Zhang","code":""},{"path":"/reference/read_remote_registry.html","id":null,"dir":"Reference","previous_headings":"","what":"read_remote_registry — read_remote_registry","title":"read_remote_registry — read_remote_registry","text":"read remote module registration files","code":""},{"path":"/reference/read_remote_registry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"read_remote_registry — read_remote_registry","text":"","code":"read_remote_registry(source, collection)"},{"path":"/reference/read_remote_registry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"read_remote_registry — read_remote_registry","text":"source remote source, e.g gee appeears collection collection product name","code":""},{"path":"/reference/read_remote_registry.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"read_remote_registry — read_remote_registry","text":"list containing original_name, pecan_name, scale, qc, projection raw_mimetype, raw_formatname pro_mimetype, pro_formatname, coordtype","code":""},{"path":"/reference/read_remote_registry.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"read_remote_registry — read_remote_registry","text":"Istem Fer","code":""},{"path":"/reference/read_remote_registry.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"read_remote_registry — read_remote_registry","text":"","code":"if (FALSE) { # \\dontrun{  read_remote_registry(   \"gee\",   \"COPERNICUS/S2_SR\") } # }"},{"path":"/reference/regrid.html","id":null,"dir":"Reference","previous_headings":"","what":"regrid — regrid","title":"regrid — regrid","text":"Regrid dataset even grid","code":""},{"path":"/reference/regrid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"regrid — regrid","text":"","code":"regrid(latlon.data)"},{"path":"/reference/regrid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"regrid — regrid","text":"latlon.data dataframe lat, lon, value regridded","code":""},{"path":"/reference/regrid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"regrid — regrid","text":"dataframe regridded data","code":""},{"path":"/reference/regrid.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"regrid — regrid","text":"David LeBauer","code":""},{"path":"/reference/remote_process.html","id":null,"dir":"Reference","previous_headings":"","what":"remote_process — remote_process","title":"remote_process — remote_process","text":"call rp_control (RpTools Python package) store output BETY","code":""},{"path":"/reference/remote_process.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"remote_process — remote_process","text":"","code":"remote_process(settings)"},{"path":"/reference/remote_process.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"remote_process — remote_process","text":"settings PEcAn settings list containing remotedata tags: source, collection, scale, projection, qc, algorithm, credfile, out_get_data, out_process_data, overwrite","code":""},{"path":"/reference/remote_process.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"remote_process — remote_process","text":"Ayush Prasad, Istem Fer","code":""},{"path":"/reference/remote_process.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"remote_process — remote_process","text":"","code":"if (FALSE) { # \\dontrun{ remote_process(settings) } # }"},{"path":"/reference/remotedata_db_check.html","id":null,"dir":"Reference","previous_headings":"","what":"remotedata_db_check — remotedata_db_check","title":"remotedata_db_check — remotedata_db_check","text":"check status requested data DB","code":""},{"path":"/reference/remotedata_db_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"remotedata_db_check — remotedata_db_check","text":"","code":"remotedata_db_check(   raw_file_name,   pro_file_name,   start,   end,   siteid,   siteid_short,   out_get_data,   algorithm,   out_process_data,   overwrite,   dbcon )"},{"path":"/reference/remotedata_db_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"remotedata_db_check — remotedata_db_check","text":"raw_file_name raw_file_name pro_file_name pro_file_name start start date requested user end end date requested user siteid siteid site siteid_short short form siteid out_get_data out_get_data algorithm algorithm out_process_data out_process_data overwrite overwrite dbcon BETYdb con","code":""},{"path":"/reference/remotedata_db_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"remotedata_db_check — remotedata_db_check","text":"list containing remotefile_check_flag, start, end, stage_get_data, write_raw_start, write_raw_end, raw_merge, existing_raw_file_path, stage_process_data, write_pro_start, write_pro_end, pro_merge, input_file, existing_pro_file_path, raw_check, pro_check","code":""},{"path":"/reference/remotedata_db_check.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"remotedata_db_check — remotedata_db_check","text":"Ayush Prasad","code":""},{"path":[]},{"path":"/reference/remotedata_db_insert.html","id":null,"dir":"Reference","previous_headings":"","what":"Insert the output data returned from rp_control into BETYdb — remotedata_db_insert","title":"Insert the output data returned from rp_control into BETYdb — remotedata_db_insert","text":"Insert output data returned rp_control BETYdb","code":""},{"path":"/reference/remotedata_db_insert.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Insert the output data returned from rp_control into BETYdb — remotedata_db_insert","text":"","code":"remotedata_db_insert(   output,   remotefile_check_flag,   siteid,   out_get_data,   out_process_data,   write_raw_start,   write_raw_end,   write_pro_start,   write_pro_end,   raw_check,   pro_check,   raw_mimetype,   raw_formatname,   pro_mimetype,   pro_formatname,   dbcon )"},{"path":"/reference/remotedata_db_insert.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Insert the output data returned from rp_control into BETYdb — remotedata_db_insert","text":"output output list rp_control remotefile_check_flag remotefile_check_flag siteid siteid out_get_data out_get_data out_process_data out_process_data write_raw_start write_raw_start, start date raw file write_raw_end write_raw_end, end date raw file write_pro_start write_pro_start write_pro_end write_pro_end raw_check id, site_id, name, start_date, end_date, existing raw file inputs table file_path dbfiles tables pro_check pro_check  id, site_id, name, start_date, end_date, existing processed file inputs table file_path dbfiles tables raw_mimetype raw_mimetype raw_formatname raw_formatname pro_mimetype pro_mimetype pro_formatname pro_formatname dbcon BETYdb con","code":""},{"path":"/reference/remotedata_db_insert.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Insert the output data returned from rp_control into BETYdb — remotedata_db_insert","text":"list containing raw_id, raw_path, pro_id, pro_path","code":""},{"path":"/reference/remotedata_db_insert.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Insert the output data returned from rp_control into BETYdb — remotedata_db_insert","text":"Ayush Prasad","code":""},{"path":[]},{"path":"/reference/set_stage.html","id":null,"dir":"Reference","previous_headings":"","what":"set_stage — set_stage","title":"set_stage — set_stage","text":"set dates, stage merge status remote data download","code":""},{"path":"/reference/set_stage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"set_stage — set_stage","text":"","code":"set_stage(result, req_start, req_end, stage)"},{"path":"/reference/set_stage.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"set_stage — set_stage","text":"result dataframe containing id, site_id, name, start_date, end_date inputs table file_path dbfiles table req_start start date requested user req_end end date requested user stage stage needs set, get_remote_data process_remote_data","code":""},{"path":"/reference/set_stage.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"set_stage — set_stage","text":"list containing req_start, req_end, stage, merge, write_start, write_end","code":""},{"path":"/reference/set_stage.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"set_stage — set_stage","text":"Ayush Prasad","code":""},{"path":"/reference/set_stage.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"set_stage — set_stage","text":"","code":"if (FALSE) { # \\dontrun{ raw_check <- set_stage(   result,   req_start,   req_end,   get_remote_data) } # }"},{"path":"/news/index.html","id":"pecandataremote-191","dir":"Changelog","previous_headings":"","what":"PEcAn.data.remote 1.9.1","title":"PEcAn.data.remote 1.9.1","text":"skip_download (default FALSE) work offline existing file named “LAI.csv”. boundary (default NULL, ie effect) set upper lower quantiles trimming LAI data","code":""},{"path":"/news/index.html","id":"pecandataremote-190","dir":"Changelog","previous_headings":"","what":"PEcAn.data.remote 1.9.0","title":"PEcAn.data.remote 1.9.0","text":"Refactored GEDI, LAI, SMAP workflows efficient parallel processing Added GEDI_L4A* functions work footprint-level GEDI biomass data","code":""},{"path":[]},{"path":"/news/index.html","id":"internal-changes-1-8-0","dir":"Changelog","previous_headings":"","what":"Internal changes","title":"PEcAn.data.remote 1.8.0","text":"call_MODIS now checks QC flags using base R functions, therefore longer depends binaryLogic package.","code":""},{"path":"/news/index.html","id":"pecandataremote-171","dir":"Changelog","previous_headings":"","what":"PEcAn.data.remote 1.7.1","title":"PEcAn.data.remote 1.7.1","text":"changes 1.7.1 earlier recorded single file PEcAn packages; please see https://github.com/PecanProject/pecan/blob/v1.7.1/CHANGELOG.md details.","code":""}]
