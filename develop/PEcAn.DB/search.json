[{"path":"/articles/betydb_access.html","id":"pecan-db-functions","dir":"Articles","previous_headings":"","what":"PEcAn.DB functions","title":"BETYdb Access","text":"","code":"settings <-list(database = list(bety = list(driver = \"PostgreSQL\", user = \"bety\", dbname = \"bety\", password = \"bety\")))  # equivalent to standard method to load PEcAn settings: # settings <- read.settings(\"pecan.xml\")  library(PEcAn.DB) require(RPostgreSQL) dbcon <- db.open(settings$database$bety)  miscanthus <- db.query(\"select lat, lon, date, trait, units, mean from traits_and_yields_view where genus = 'Miscanthus';\", con = dbcon)  salix_spp <- query.pft_species(pft = \"salix\", modeltype = \"BIOCRO\", con = dbcon)  salix_vcmax <- query.trait.data(trait = \"Vcmax\", spstr = vecpaste(salix_spp$id), con = dbcon)"},{"path":"/articles/betydb_access.html","id":"r-dplyr-interface","dir":"Articles","previous_headings":"","what":"R dplyr interface","title":"BETYdb Access","text":"Documentation dplyr interface databases provided dplyr vignette","code":"library(dplyr)  d <- settings$database$bety[c(\"dbname\", \"password\", \"host\", \"user\")] bety <- DBI::dbConnect(     drv = RPostgres::Postgres(),     host = d$host,     user = d$user,     password = d$password,     dbname = d$dbname ) # (Note: you could also do this as `bety <- db.open(settings$database$bety)`, # but we show the dbConnect version to emphasize that you can, if you wish, # access BETY without using PEcAn)   species <- tbl(bety, 'species') %>%    select(id, scientificname, genus) %>%    filter(genus == \"Miscanthus\") %>%    mutate(specie_id = id)   yields <-tbl(bety, 'yields') %>%   select(date, mean, site_id, specie_id)  sites <- tbl(bety, 'sites') %>%    select(id, sitename, city, country) %>%    mutate(site_id = id)   mxgdata <- inner_join(species, yields, by = 'specie_id') %>%   left_join(sites, by = 'site_id') %>%    select(-ends_with(\".x\"), -ends_with(\".y\")) %>% # drops duplicate rows   collect()"},{"path":"/articles/betydb_access.html","id":"ropensci-traits-api","dir":"Articles","previous_headings":"","what":"rOpensci traits API","title":"BETYdb Access","text":"","code":"# install_github(\"ropensci/traits\") library(\"traits\")  out <- betydb_search(query = \"Switchgrass Yield\")   library(\"dplyr\") out %>%   group_by(id) %>%   summarise(mean_result = mean(as.numeric(mean), na.rm = TRUE)) %>%   arrange(desc(mean_result))"},{"path":"/articles/create_sites.geometry.html","id":"load-libraries","dir":"Articles","previous_headings":"","what":"Load Libraries","title":"Create PostGIS polygon","text":"","code":"library(ggplot2) library(data.table) library(rgbif) library(knitr)"},{"path":"/articles/create_sites.geometry.html","id":"select-lat-and-lon-points-for-champaign-county-boundary","dir":"Articles","previous_headings":"","what":"Select lat and lon points for Champaign County Boundary","title":"Create PostGIS polygon","text":"","code":"d <- data.table(map_data(\"county\")) champaign <- d[region == \"illinois\" & subregion == \"champaign\"]  kable(champaign)"},{"path":"/articles/create_sites.geometry.html","id":"query-elevation-points","dir":"Articles","previous_headings":"","what":"Query Elevation points","title":"Create PostGIS polygon","text":"","code":"### for PostGIS, need polygon to return to start point champaign <- rbind(champaign, champaign[1])  ## need to get key from Google Maps API ## I've put mine in a ~/.googlemapskey key <- readLines(con = \"~/.googlemapskey\") champaign_pts <- data.table(champaign[,elevation(latitude = lat, longitude = long, key = key)])  kable(champaign_pts, caption = \"Table with elevations\")"},{"path":"/articles/create_sites.geometry.html","id":"define-boundary-in-postgis","dir":"Articles","previous_headings":"","what":"Define boundary in postGIS","title":"Create PostGIS polygon","text":"","code":"boundary <- champaign_pts[,paste(longitude, latitude, elevation, collapse = \",\")]  writeLines(boundary)"},{"path":"/articles/create_sites.geometry.html","id":"define-postgis-geom","dir":"Articles","previous_headings":"","what":"Define PostGIS geom","title":"Create PostGIS polygon","text":"Use srid = 4326","code":"geometry <- paste0(\"ST_SetSRID(ST_MakePolygon(ST_GeomFromText('LINESTRING(\", boundary , \")')), 4326)\")  writeLines(geometry)"},{"path":"/articles/create_sites.geometry.html","id":"insert-statement","dir":"Articles","previous_headings":"Define PostGIS geom","what":"insert statement","title":"Create PostGIS polygon","text":"","code":"insert_polygon <- paste0(\"INSERT into sites (sitename, geometry) VALUES ('Champaign County', \", geometry, \");\") writeLines(insert_polygon)"},{"path":"/articles/create_sites.geometry.html","id":"update-geom-statement","dir":"Articles","previous_headings":"Define PostGIS geom","what":"Update geom statement","title":"Create PostGIS polygon","text":"","code":"update_polygon <- paste0(\"update sites set geometry = \", geometry , \" where sitename = 'Champaign County';\") writeLines(update_polygon)"},{"path":"/articles/create_sites.geometry.html","id":"insert-into-betydb","dir":"Articles","previous_headings":"","what":"Insert into BETYdb","title":"Create PostGIS polygon","text":"","code":"library(PEcAn.DB) library(RPostgreSQL) #settings <- read.settings('settings.xml') settings <-list(database = list(bety = list(driver = \"PostgreSQL\", user = \"bety\", dbname = \"bety\", password = \"bety\")))  db.query(insert_polygon, con = db.open(settings$database$bety))"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David LeBauer. Author, maintainer. Mike Dietze. Author. Rob Kooper. Author. Shawn Serbin. Author. Elizabeth Cowdery. Author. Ankur Desai. Author. Istem Fer. Author. Alexey Shiklomanov. Author. Tony Gardella. Author. Chris Black. Author. Liam Burke. Author. Ryan Kelly. Author. Dan Wang. Author. Carl Davidson. Author. Xiaohui Feng. Author. Shashank Singh. Author. University Illinois, NCSA. Copyright holder.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"LeBauer D, Dietze M, Kooper R, Serbin S, Cowdery E, Desai , Fer , Shiklomanov , Gardella T, Black C, Burke L, Kelly R, Wang D, Davidson C, Feng X, Singh S (2025). PEcAn.DB: PEcAn Functions Used Ecological Forecasts Reanalysis. R package version 1.8.1.9000, https://pecanproject.github.io.","code":"@Manual{,   title = {PEcAn.DB: PEcAn Functions Used for Ecological Forecasts and Reanalysis},   author = {David LeBauer and Mike Dietze and Rob Kooper and Shawn Serbin and Elizabeth Cowdery and Ankur Desai and Istem Fer and Alexey Shiklomanov and Tony Gardella and Chris Black and Liam Burke and Ryan Kelly and Dan Wang and Carl Davidson and Xiaohui Feng and Shashank Singh},   year = {2025},   note = {R package version 1.8.1.9000},   url = {https://pecanproject.github.io}, }"},{"path":"/index.html","id":"pecandb","dir":"","previous_headings":"","what":"PEcAn Functions Used for Ecological Forecasts and Reanalysis","title":"PEcAn Functions Used for Ecological Forecasts and Reanalysis","text":"PEcAn Functions Used Ecological Forecasts Reanalysis","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"PEcAn Functions Used for Ecological Forecasts and Reanalysis","text":"can install development version PEcAn.DB r-universe like : can install directly GitHub remotes package like :","code":"# Enable repository from pecanproject options(repos = c(   pecanproject = 'https://pecanproject.r-universe.dev',   CRAN = 'https://cloud.r-project.org')) # Download and install PEcAn.DB in R install.packages('PEcAn.DB') library(remotes) install_github('pecanproject/pecan',  subdir = \"base/db\")"},{"path":"/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"PEcAn Functions Used for Ecological Forecasts and Reanalysis","text":"basic example shows solve common problem:","code":"library(PEcAn.DB) ## basic example code"},{"path":"/reference/PEcAn.DB-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Database functions for PEcAn, the Predictive Ecosystem Analyzer — PEcAn.DB-package","title":"Database functions for PEcAn, the Predictive Ecosystem Analyzer — PEcAn.DB-package","text":"package provides interface PEcAn BETY database. usage examples, please see vignette(\"betydb_access\")","code":""},{"path":[]},{"path":"/reference/PEcAn.DB-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Database functions for PEcAn, the Predictive Ecosystem Analyzer — PEcAn.DB-package","text":"Maintainer: David LeBauer dlebauer@email.arizona.edu Authors: Mike Dietze dietze@bu.edu Rob Kooper kooper@illinois.edu Shawn Serbin sserbin@bnl.gov Elizabeth Cowdery ecowdery@bu.edu Ankur Desai desai@aos.wisc.edu Istem Fer istem.fer@fmi.fi Alexey Shiklomanov alexey.shiklomanov@pnnl.gov Tony Gardella tonygard@bu.edu Chris Black chris@ckblack.org Liam Burke liam.burke24@gmail.com Ryan Kelly rykelly@bu.edu Dan Wang Carl Davidson davids14@illinois.edu Xiaohui Feng feng22@illinois.edu Shashank Singh shashanksingh819@gmail.com contributors: University Illinois, NCSA [copyright holder]","code":""},{"path":"/reference/append.covariate.html","id":null,"dir":"Reference","previous_headings":"","what":"Append covariate data as a column within a table — append.covariate","title":"Append covariate data as a column within a table — append.covariate","text":"append.covariate appends data frame covariates new column data frame   trait data. event trait several covariates available, first one found   (.e. lowest row number) take precedence","code":""},{"path":"/reference/append.covariate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Append covariate data as a column within a table — append.covariate","text":"","code":"append.covariate(data, column.name, covariates.data)"},{"path":"/reference/append.covariate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Append covariate data as a column within a table — append.covariate","text":"data trait dataframe appended . column.name name covariate appear appended column covariates.data one tables covariate data, ordered precedence assume event trait covariates across multiple tables. tables must contain 'id' 'level' column, minimum.","code":""},{"path":"/reference/append.covariate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Append covariate data as a column within a table — append.covariate","text":"Carl Davidson, Ryan Kelly","code":""},{"path":"/reference/arrhenius.scaling.traits.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply Arrhenius scaling to 25 degC for temperature-dependent traits — arrhenius.scaling.traits","title":"Apply Arrhenius scaling to 25 degC for temperature-dependent traits — arrhenius.scaling.traits","text":"Apply Arrhenius scaling 25 degC temperature-dependent traits","code":""},{"path":"/reference/arrhenius.scaling.traits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply Arrhenius scaling to 25 degC for temperature-dependent traits — arrhenius.scaling.traits","text":"","code":"arrhenius.scaling.traits(   data,   covariates,   temp.covariates,   new.temp = 25,   missing.temp = 25 )"},{"path":"/reference/arrhenius.scaling.traits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply Arrhenius scaling to 25 degC for temperature-dependent traits — arrhenius.scaling.traits","text":"data data frame data scale, returned query.data() covariates data frame covariates, returned query.covariates(). Note data matching covariates unchanged. temp.covariates names covariates used adjust temperature; length > 1, order matters (first used preferentially) new.temp reference temperature scaled traits. Curerntly 25 degC missing.temp temperature assumed traits covariate found. Curerntly 25 degC","code":""},{"path":"/reference/arrhenius.scaling.traits.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Apply Arrhenius scaling to 25 degC for temperature-dependent traits — arrhenius.scaling.traits","text":"Carl Davidson, David LeBauer, Ryan Kelly","code":""},{"path":"/reference/assign.treatments.html","id":null,"dir":"Reference","previous_headings":"","what":"assign.treatments — assign.treatments","title":"assign.treatments — assign.treatments","text":"Change treatments sequential integers","code":""},{"path":"/reference/assign.treatments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"assign.treatments — assign.treatments","text":"","code":"assign.treatments(data)"},{"path":"/reference/assign.treatments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"assign.treatments — assign.treatments","text":"data input data","code":""},{"path":"/reference/assign.treatments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"assign.treatments — assign.treatments","text":"dataframe sequential treatments","code":""},{"path":"/reference/assign.treatments.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"assign.treatments — assign.treatments","text":"Assigns control treatments value, assigns unique treatments within site. site required control treatment. algorithm (incorrectly) assumes site unique set experimental treatments. assumption required data BETYdb always consistently name treatments quantity managements table. Also avoids need estimate treatment site interactions meta analysis model. model uses data control treatment estimate model parameters impact assumption minimal.","code":""},{"path":"/reference/assign.treatments.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"assign.treatments — assign.treatments","text":"David LeBauer, Carl Davidson, Alexey Shiklomanov","code":""},{"path":"/reference/bety2pecan.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert BETY variable names to MsTMIP and subsequently PEcAn standard names — bety2pecan","title":"Convert BETY variable names to MsTMIP and subsequently PEcAn standard names — bety2pecan","text":"Convert BETY variable names MsTMIP subsequently PEcAn standard names","code":""},{"path":"/reference/bety2pecan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert BETY variable names to MsTMIP and subsequently PEcAn standard names — bety2pecan","text":"","code":"bety2pecan(vars_bety)"},{"path":"/reference/bety2pecan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert BETY variable names to MsTMIP and subsequently PEcAn standard names — bety2pecan","text":"vars_bety data frame variable names units","code":""},{"path":"/reference/bety2pecan.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert BETY variable names to MsTMIP and subsequently PEcAn standard names — bety2pecan","text":"Betsy Cowdery","code":""},{"path":"/reference/betyConnect.html","id":null,"dir":"Reference","previous_headings":"","what":"Connect to bety using current PEcAn configuration — betyConnect","title":"Connect to bety using current PEcAn configuration — betyConnect","text":"Connect bety using current PEcAn configuration","code":""},{"path":"/reference/betyConnect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Connect to bety using current PEcAn configuration — betyConnect","text":"","code":"betyConnect(php.config = \"../../web/config.php\")"},{"path":"/reference/betyConnect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Connect to bety using current PEcAn configuration — betyConnect","text":"php.config Path `config.php`","code":""},{"path":"/reference/check.lists.html","id":null,"dir":"Reference","previous_headings":"","what":"Compares two lists — check.lists","title":"Compares two lists — check.lists","text":"Check two lists. Identical work since one can loaded database CSV file.","code":""},{"path":"/reference/check.lists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compares two lists — check.lists","text":"","code":"check.lists(x, y, filename = \"species.csv\")"},{"path":"/reference/check.lists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compares two lists — check.lists","text":"x first list y second list filename one \"species.csv\" \"cultivars.csv\"","code":""},{"path":"/reference/check.lists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compares two lists — check.lists","text":"true two lists ","code":""},{"path":"/reference/check.lists.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compares two lists — check.lists","text":"Rob Kooper","code":""},{"path":"/reference/check_missing_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for Missing or Empty Files in Conversion Results — check_missing_files","title":"Check for Missing or Empty Files in Conversion Results — check_missing_files","text":"function inspects file paths list data frames (typically produced download conversion routine) ensure file present non-empty. Specifically, checks whether file path missing file size zero, logs error files detected. also normalizes `existing.input` `existing.dbfile` returned list data frames.","code":""},{"path":"/reference/check_missing_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for Missing or Empty Files in Conversion Results — check_missing_files","text":"","code":"check_missing_files(result, existing.input = NULL, existing.dbfile = NULL)"},{"path":"/reference/check_missing_files.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for Missing or Empty Files in Conversion Results — check_missing_files","text":"result list data frames containing file information. data frame expected column named `file` absolute file paths created data-conversion download function. example, might structure returned \"download_X\" \"met2model_X\" function invoked via [convert_input()]. existing.input data frame list data frames (possibly zero rows) representing input records BETY `inputs` table match (partially match) data added. converted list data frames already. existing.dbfile data frame list data frames (possibly zero rows) representing dbfile records BETY `dbfiles` table match (partially match) data added. also converted list data frames already.","code":""},{"path":"/reference/check_missing_files.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for Missing or Empty Files in Conversion Results — check_missing_files","text":"list containing: list data frames `existing.input` list data frames `existing.dbfile`","code":""},{"path":"/reference/check_missing_files.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check for Missing or Empty Files in Conversion Results — check_missing_files","text":"function calculates file size file specified `result` data frames. file path missing (`NA`) file size zero, function raises fatal error (via [PEcAn.logger::logger.severe]) indicating expected file either nonexistent empty. issues found, merely ensures `existing.input` `existing.dbfile` wrapped list consistent downstream usage.","code":""},{"path":"/reference/check_missing_files.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check for Missing or Empty Files in Conversion Results — check_missing_files","text":"Betsy Cowdery, Michael Dietze, Ankur Desai, Tony Gardella, Luke Dramko","code":""},{"path":"/reference/clone_pft.html","id":null,"dir":"Reference","previous_headings":"","what":"Duplicate existing pft with associated priors, species, and cultivars — clone_pft","title":"Duplicate existing pft with associated priors, species, and cultivars — clone_pft","text":"Creates new pft duplicate existing pft, including relationships priors, species, cultivars () existing pft. function mimics 'clone pft' button PFTs record view page BETYdb web interface PFTs aggregate >=1 species, adds ability clone cultivar associations.","code":""},{"path":"/reference/clone_pft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Duplicate existing pft with associated priors, species, and cultivars — clone_pft","text":"","code":"clone_pft(parent.pft.name, new.pft.name, new.pft.definition, settings)"},{"path":"/reference/clone_pft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Duplicate existing pft with associated priors, species, and cultivars — clone_pft","text":"parent.pft.name name PFT duplicate new.pft.name name new PFT. Must parent.pft.name new.pft.definition text new PFT's definition field. settings PEcAn settings list, used BETYdb connection parameters","code":""},{"path":"/reference/clone_pft.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Duplicate existing pft with associated priors, species, and cultivars — clone_pft","text":"ID newly created pft database, creates new PFT side effect","code":""},{"path":"/reference/clone_pft.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Duplicate existing pft with associated priors, species, and cultivars — clone_pft","text":"David LeBauer, Chris Black","code":""},{"path":"/reference/clone_pft.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Duplicate existing pft with associated priors, species, and cultivars — clone_pft","text":"","code":"if (FALSE) { # \\dontrun{ clone_pft(parent.pft.name    = \"tempdecid\",           new.pft.name       = \"mytempdecid\",           new.pft.definition = \"mytempdecid is a new pft\",           settings = pecan_settings_list) } # }"},{"path":"/reference/convert_input.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert between formats, reusing existing files where possible — convert_input","title":"Convert between formats, reusing existing files where possible — convert_input","text":"convert_input relatively generic function applies function fcn inserts record database. primarily designed converting meteorological data formats can used observed data, forecasts, ensembles forecasts. minimize downloading storing duplicate data, first checks see given file already database applying fcn.","code":""},{"path":"/reference/convert_input.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert between formats, reusing existing files where possible — convert_input","text":"","code":"convert_input(   input.id,   outfolder,   formatname,   mimetype,   site.id,   start_date,   end_date,   pkg,   fcn,   con = con,   host,   write = TRUE,   format.vars,   overwrite = FALSE,   exact.dates = FALSE,   allow.conflicting.dates = TRUE,   insert.new.file = FALSE,   pattern = NULL,   forecast = FALSE,   ensemble = FALSE,   ensemble_name = NULL,   dbparms = NULL,   ... )"},{"path":"/reference/convert_input.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert between formats, reusing existing files where possible — convert_input","text":"input.id database id input file parent file processed .  parent data, different format. outfolder directory files generated functions called convert_input placed formatname data product specific format name mimetype data product specific file format site.id id site start_date Start date data requested processed end_date End date data requested processed pkg package function executed (string) fcn function executed records output file found database. (string) con Database connection object host Named list identifying machine conversion performed. Currently host$name host$Rbinary used convert_input,  whole list passed functions write Logical: Write new file records database? format.vars Passed arguments fcn overwrite Logical: file already exists, create fresh copy? Passed along fcn. exact.dates Ignore time-span appending enforce exact start end dates database input file? (logical) allow.conflicting.dates overlapping years ignore time-span appending exist separate input files? (logical) insert.new.file Logical: force creation new database record even one already exists? pattern regular expression, passed dbfile.input.check, used match name input file. forecast Logical: data product forecast? ensemble integer representing number ensembles, FALSE data product ensemble. ensemble_name convert_input called iteratively ensemble, ensemble_name contains identifying name/number ensemble. dbparms list parameters use opening database connection ... Additional arguments, passed unchanged fcn","code":""},{"path":"/reference/convert_input.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert between formats, reusing existing files where possible — convert_input","text":"list two BETY IDs (input.id, dbfile.id) identifying pre-existing file one available, newly created file .  id may vector ids function processing entire ensemble .","code":""},{"path":"/reference/convert_input.html","id":"executing-the-function","dir":"Reference","previous_headings":"","what":"Executing the function","title":"Convert between formats, reusing existing files where possible — convert_input","text":"convert_input executes function fcn package pkg via PEcAn.remote::remote.execute.R.  additional arguments passed convert_input (...) turn passed along fcn arguments.  addition, several named arguments convert_input passed along fcn.  command execute fcn built string.","code":""},{"path":"/reference/convert_input.html","id":"database-files","dir":"Reference","previous_headings":"","what":"Database files","title":"Convert between formats, reusing existing files where possible — convert_input","text":"two kinds database records (different tables) represent given data file file system.  input file contains information contents data file.  dbfile contains machine spacific information given input file, file path.  duplicates data files given input can multiple different machines, can one dbfile given input file.","code":""},{"path":"/reference/convert_input.html","id":"time-span-appending","dir":"Reference","previous_headings":"","what":"Time-span appending","title":"Convert between formats, reusing existing files where possible — convert_input","text":"default, convert_input tries optimize download data products downloading years data present current machine.  (example, files 2004-2008 exist given data product exist machine user requests 2006-2010, function download data 2009 2010).  year-long data files, year exists separate file. database input file contains records bounds range stored years.  data optimization can turned overriding default values exact.dates allow.conflicting.dates.","code":""},{"path":"/reference/convert_input.html","id":"forecast-data","dir":"Reference","previous_headings":"","what":"Forecast data","title":"Convert between formats, reusing existing files where possible — convert_input","text":"flag forecast TRUE, convert_input treats data forecast data.  Forecast data undergo time span appending.","code":""},{"path":"/reference/convert_input.html","id":"ensembles","dir":"Reference","previous_headings":"","what":"Ensembles","title":"Convert between formats, reusing existing files where possible — convert_input","text":"convert_input capability handle ensembles met data.  ensemble = integer > 1, convert_input checks database records ensemble members, calls fcn least one missing.  convert_input assumes fcn return records ensembles. convert_input can also called iteratevely ensemble member.  case ensemble_name contains unique identifying name/number ensemble processed.","code":""},{"path":"/reference/convert_input.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert between formats, reusing existing files where possible — convert_input","text":"Betsy Cowdery, Michael Dietze, Ankur Desai, Tony Gardella, Luke Dramko","code":""},{"path":"/reference/db.close.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic function to close a database connection — db.close","title":"Generic function to close a database connection — db.close","text":"Close previously opened connection database.","code":""},{"path":"/reference/db.close.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic function to close a database connection — db.close","text":"","code":"db.close(con, showWarnings = TRUE)"},{"path":"/reference/db.close.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic function to close a database connection — db.close","text":"con database connection closed showWarnings logical: report possible issues connection?","code":""},{"path":"/reference/db.close.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generic function to close a database connection — db.close","text":"`TRUE`, invisibly (see [DBI::dbDisconnect()])","code":""},{"path":"/reference/db.close.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generic function to close a database connection — db.close","text":"Rob Kooper","code":""},{"path":"/reference/db.close.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generic function to close a database connection — db.close","text":"","code":"if (FALSE) { # \\dontrun{ db.close(con) } # }"},{"path":"/reference/db.exists.html","id":null,"dir":"Reference","previous_headings":"","what":"Test connection to database — db.exists","title":"Test connection to database — db.exists","text":"Useful run tests depend database connection exists","code":""},{"path":"/reference/db.exists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test connection to database — db.exists","text":"","code":"db.exists(params, write = TRUE, table = NA)"},{"path":"/reference/db.exists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test connection to database — db.exists","text":"params database connection information write logical: test whether write access? table name database table check","code":""},{"path":"/reference/db.exists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test connection to database — db.exists","text":"TRUE database connection works; else FALSE","code":""},{"path":"/reference/db.exists.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Test connection to database — db.exists","text":"David LeBauer, Rob Kooper","code":""},{"path":"/reference/db.getShowQueries.html","id":null,"dir":"Reference","previous_headings":"","what":"db.getShowQueries — db.getShowQueries","title":"db.getShowQueries — db.getShowQueries","text":"Returns queries shown executed","code":""},{"path":"/reference/db.getShowQueries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"db.getShowQueries — db.getShowQueries","text":"","code":"db.getShowQueries()"},{"path":"/reference/db.getShowQueries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"db.getShowQueries — db.getShowQueries","text":"return TRUE queries shown","code":""},{"path":"/reference/db.getShowQueries.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"db.getShowQueries — db.getShowQueries","text":"Rob Kooper","code":""},{"path":"/reference/db.open.html","id":null,"dir":"Reference","previous_headings":"","what":"Open a database connection — db.open","title":"Open a database connection — db.open","text":"Create connection database using specified parameters. `params` list passed arguments [DBI::dbConnect()].","code":""},{"path":"/reference/db.open.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Open a database connection — db.open","text":"","code":"db.open(params)"},{"path":"/reference/db.open.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Open a database connection — db.open","text":"params Named list database connection options. See details","code":""},{"path":"/reference/db.open.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Open a database connection — db.open","text":"Database connection object","code":""},{"path":"/reference/db.open.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Open a database connection — db.open","text":"Typical arguments follows: - `driver` – name database driver. `\"PostgreSQL\"` `\"Postgres\"` supported. driver specified, default `\"PostgreSQL\"`. - `user` – database username. local instances PEcAn, usually `\"bety\"`. - `password` – database password. local instances PEcAn, usually `\"bety\"`. - `host` – database hostname. local instances PEcAn, usually `\"localhost\"`. Inside PEcAn Docker stack, may `\"postgres\"`. - `port` (optional) – port accessing database. omitted, use PostgreSQL default (5432).","code":""},{"path":"/reference/db.open.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Open a database connection — db.open","text":"Rob Kooper","code":""},{"path":"/reference/db.open.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Open a database connection — db.open","text":"","code":"if (FALSE) { # \\dontrun{ db.open(settings$database$bety) } # }"},{"path":"/reference/db.print.connections.html","id":null,"dir":"Reference","previous_headings":"","what":"Debug leaked connections — db.print.connections","title":"Debug leaked connections — db.print.connections","text":"Prints number connections opened well connections never closes.","code":""},{"path":"/reference/db.print.connections.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Debug leaked connections — db.print.connections","text":"","code":"db.print.connections()"},{"path":"/reference/db.print.connections.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Debug leaked connections — db.print.connections","text":"Rob Kooper","code":""},{"path":"/reference/db.print.connections.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Debug leaked connections — db.print.connections","text":"","code":"if (FALSE) { # \\dontrun{ db.print.connections() } # }"},{"path":"/reference/db.query.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic function to query database — db.query","title":"Generic function to query database — db.query","text":"Given connection query, return query data frame. Either con params need specified. specified use con.","code":""},{"path":"/reference/db.query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic function to query database — db.query","text":"","code":"db.query(query, con = NULL, params = NULL, values = NULL)"},{"path":"/reference/db.query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic function to query database — db.query","text":"query SQL query string con Database connection object params Named list database connection parameters. See `params` argument [db.open()]. values using prepared statements, list values substitute query. `NULL` (default), execute query directly. See function's \"Details\", documentation [DBI::dbBind()].","code":""},{"path":"/reference/db.query.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generic function to query database — db.query","text":"data frame query results","code":""},{"path":"/reference/db.query.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generic function to query database — db.query","text":"function supports prepared statements, provide way pass data SQL queries without risk SQL injection attacks. Whenever tempted something like : “` db.query(paste0(   \"SELECT * table mycol = \", somevalue,   \" othercol = \", othervalue ), con = con) “` ...use prepared query instead: “` db.query(   \"SELECT * table mycol = $1 othercol = $2\",   values = list(somevalue, othervalue),   con = con ) “` Besides preventing SQL injections, prepared statements also ensure input target types compatible. Prepared statements provide efficient way operate multiple values . example, following return models whose revision either \"git\", \"46\", \"unk\": “` db.query(   \"SELECT * models revision = $1\",   values = list(c(\"git\", \"46\", \"unk\")),   con = con ) “` ...example inserting multiple values given trait given species: “` db.query(   \"INSERT traits (specie_id, variable_id, mean, n) VALUES ($1, $2, $3)\",   values = list(938, 396, c(1.7, 3.9, 4.5), 1),   con = con ) “` Note prepared statements **can used select tables columns**. words, following _will work_ following placeholders, valid one `$5`: “` # work! db.query(   \"SELECT $1, $2 $3 $4 = $5\",   values = list(\"col1\", \"col2\", \"mytable\", \"somecolumn\", \"somevalue\") ) “` Note prepared statements **supported `RPostgreSQL` package**; newer `RPostgres` package.","code":""},{"path":"/reference/db.query.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generic function to query database — db.query","text":"Rob Kooper, Alexey Shiklomanov","code":""},{"path":"/reference/db.query.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generic function to query database — db.query","text":"","code":"if (FALSE) { # \\dontrun{ db.query(\"SELECT count(id) FROM traits;\", params = settings$database$bety)  # Prepared statements con <- db.open(settings$database$bety) db.query(   \"SELECT * FROM table WHERE mycol = $1 AND othercol = $2\",   values = list(somevalue, othervalue),   con = con )  # Select multiple values at once; rbind the result db.query(   \"SELECT * FROM models WHERE revision = $1\",   values = list(c(\"git\", \"46\", \"unk\")),   con = con )  # Efficiently insert multiple values into a table db.query(   \"INSERT INTO traits (specie_id, variable_id, mean, n) VALUES ($1, $2, $3, $4)\",   values = list(938, 396, rnorm(1000), 1),   con = con ) } # }"},{"path":"/reference/db.showQueries.html","id":null,"dir":"Reference","previous_headings":"","what":"db.showQueries — db.showQueries","title":"db.showQueries — db.showQueries","text":"Sets queries shown executed","code":""},{"path":"/reference/db.showQueries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"db.showQueries — db.showQueries","text":"","code":"db.showQueries(show)"},{"path":"/reference/db.showQueries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"db.showQueries — db.showQueries","text":"show set TRUE show queries, FALSE default","code":""},{"path":"/reference/db.showQueries.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"db.showQueries — db.showQueries","text":"Useful print queries debuging SQL statements","code":""},{"path":"/reference/db.showQueries.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"db.showQueries — db.showQueries","text":"Rob Kooper","code":""},{"path":"/reference/dbHostInfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Database host information — dbHostInfo","title":"Database host information — dbHostInfo","text":"Database host information","code":""},{"path":"/reference/dbHostInfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Database host information — dbHostInfo","text":"","code":"dbHostInfo(bety)"},{"path":"/reference/dbHostInfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Database host information — dbHostInfo","text":"bety BETYdb connection, opened `betyConnect()`","code":""},{"path":"/reference/db_merge_into.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge local data frame into SQL table — db_merge_into","title":"Merge local data frame into SQL table — db_merge_into","text":"Merge local data frame SQL table","code":""},{"path":"/reference/db_merge_into.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge local data frame into SQL table — db_merge_into","text":"","code":"db_merge_into(values, table, con, by = NULL, drop = FALSE, ...)"},{"path":"/reference/db_merge_into.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge local data frame into SQL table — db_merge_into","text":"values `data.frame` values write SQL database table Name target SQL table, character con Database connection object Character vector columns perform merge. Defaults columns `values` drop logical. `TRUE` (default), drop columns found SQL table. ... Arguments passed insert_table coerce_col_class logical, whether coerce local data columns SQL classes. Default = `TRUE.`","code":""},{"path":"/reference/db_merge_into.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge local data frame into SQL table — db_merge_into","text":"Data frame: Inner join SQL table input data frame (unevaluated \"lazy query\" table)","code":""},{"path":"/reference/db_merge_into.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge local data frame into SQL table — db_merge_into","text":"","code":"irisdb <- DBI::dbConnect(RSQLite::SQLite(), \":memory:\") dplyr::copy_to(irisdb, iris[1:10,], name = \"iris\", overwrite = TRUE) db_merge_into(iris[1:12,], \"iris\", irisdb) #> Joining with `by = join_by(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width, Species)` #> # Source:   SQL [?? x 5] #> # Database: sqlite 3.47.1 [:memory:] #>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species #>           <dbl>       <dbl>        <dbl>       <dbl> <chr>   #>  1          5.1         3.5          1.4         0.2 setosa  #>  2          4.9         3            1.4         0.2 setosa  #>  3          4.7         3.2          1.3         0.2 setosa  #>  4          4.6         3.1          1.5         0.2 setosa  #>  5          5           3.6          1.4         0.2 setosa  #>  6          5.4         3.9          1.7         0.4 setosa  #>  7          4.6         3.4          1.4         0.3 setosa  #>  8          5           3.4          1.5         0.2 setosa  #>  9          4.4         2.9          1.4         0.2 setosa  #> 10          4.9         3.1          1.5         0.1 setosa  #> 11          5.4         3.7          1.5         0.2 setosa  #> 12          4.8         3.4          1.6         0.2 setosa  dplyr::tbl(irisdb, \"iris\") %>% dplyr::count() #> # Source:   SQL [?? x 1] #> # Database: sqlite 3.47.1 [:memory:] #>       n #>   <int> #> 1    12"},{"path":"/reference/dbfile.check.html","id":null,"dir":"Reference","previous_headings":"","what":"List files associated with a container and machine exist in `dbfiles` table — dbfile.check","title":"List files associated with a container and machine exist in `dbfiles` table — dbfile.check","text":"List files associated container machine exist `dbfiles` table","code":""},{"path":"/reference/dbfile.check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List files associated with a container and machine exist in `dbfiles` table — dbfile.check","text":"","code":"dbfile.check(   type,   container.id,   con,   hostname = PEcAn.remote::fqdn(),   machine.check = TRUE,   return.all = FALSE )"},{"path":"/reference/dbfile.check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List files associated with a container and machine exist in `dbfiles` table — dbfile.check","text":"type type `dbfile`, character. Must either \"Input\", \"Posterior\", \"Model\". container.id ID container type. E.g. `type` \"Input\", correspond `id` column `inputs` table. con database connection object hostname name host file stored, default name current machine machine.check setting check file named host, otherwise check file given container id return.(Logical) `TRUE`, return files. `FALSE`, return recent files.","code":""},{"path":"/reference/dbfile.check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List files associated with a container and machine exist in `dbfiles` table — dbfile.check","text":"`data.frame` id, filename pathname files associated","code":""},{"path":"/reference/dbfile.check.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"List files associated with a container and machine exist in `dbfiles` table — dbfile.check","text":"Rob Kooper, Alexey Shiklomanov","code":""},{"path":"/reference/dbfile.check.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List files associated with a container and machine exist in `dbfiles` table — dbfile.check","text":"","code":"if (FALSE) { # \\dontrun{   dbfile.check(\"Input\", 7, dbcon) } # }"},{"path":"/reference/dbfile.file.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert between file paths and ids — dbfile.file","title":"Convert between file paths and ids — dbfile.file","text":"functions check dbfiles machines tables see file exists, return container_id (dbfile.id) full filename path (dbfile.file) first one found. none found, return NA.","code":""},{"path":"/reference/dbfile.file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert between file paths and ids — dbfile.file","text":"","code":"dbfile.file(type, id, con, hostname = PEcAn.remote::fqdn())  dbfile.id(type, file, con, hostname = PEcAn.remote::fqdn())"},{"path":"/reference/dbfile.file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert between file paths and ids — dbfile.file","text":"type type dbfile (Input, Posterior) id id container type con database connection object hostname name host file stored, default name current machine file full pathname file","code":""},{"path":"/reference/dbfile.file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert between file paths and ids — dbfile.file","text":"filename host, NA none found","code":""},{"path":"/reference/dbfile.file.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Convert between file paths and ids — dbfile.file","text":"dbfile.file(): Return full path file dbfiles table dbfile.id(): Return id container type given filename","code":""},{"path":"/reference/dbfile.file.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert between file paths and ids — dbfile.file","text":"Rob Kooper","code":""},{"path":"/reference/dbfile.file.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert between file paths and ids — dbfile.file","text":"","code":"if (FALSE) { # \\dontrun{   dbfile.file('Input', 7, dbcon) } # } if (FALSE) { # \\dontrun{   dbfile.id('Model', '/usr/local/bin/sipnet', dbcon) } # }"},{"path":"/reference/dbfile.input.check.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for a file in the input/dbfiles tables — dbfile.input.check","title":"Check for a file in the input/dbfiles tables — dbfile.input.check","text":"Function check see file exists dbfiles table input","code":""},{"path":"/reference/dbfile.input.check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for a file in the input/dbfiles tables — dbfile.input.check","text":"","code":"dbfile.input.check(   siteid,   startdate = NULL,   enddate = NULL,   mimetype,   formatname,   parentid = NA,   con,   hostname = PEcAn.remote::fqdn(),   exact.dates = FALSE,   pattern = NULL,   return.all = FALSE )"},{"path":"/reference/dbfile.input.check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for a file in the input/dbfiles tables — dbfile.input.check","text":"siteid id site data applicable startdate start date data stored file enddate end date data stored file mimetype mime-type file formatname name format distinguish simmilair mime-types parentid id parent input con database connection object hostname name host file stored, default name current machine exact.dates setting include start end date input query pattern text seach file name (default NULL = check). return.(Logical) 'TRUE', return files. 'FALSE', return recent files.","code":""},{"path":"/reference/dbfile.input.check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for a file in the input/dbfiles tables — dbfile.input.check","text":"data.frame id, filename pathname input requested","code":""},{"path":"/reference/dbfile.input.check.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check for a file in the input/dbfiles tables — dbfile.input.check","text":"check dbfiles, inputs, machines formats tables see file exists","code":""},{"path":"/reference/dbfile.input.check.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check for a file in the input/dbfiles tables — dbfile.input.check","text":"Rob Kooper, Tony Gardella, Hamze Dokoohaki","code":""},{"path":"/reference/dbfile.input.check.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check for a file in the input/dbfiles tables — dbfile.input.check","text":"","code":"if (FALSE) { # \\dontrun{   dbfile.input.check(siteid, startdate, enddate, 'application/x-RData', 'traits', dbcon) } # }"},{"path":"/reference/dbfile.input.insert.html","id":null,"dir":"Reference","previous_headings":"","what":"Insert file into tables — dbfile.input.insert","title":"Insert file into tables — dbfile.input.insert","text":"Function insert file dbfiles table input","code":""},{"path":"/reference/dbfile.input.insert.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Insert file into tables — dbfile.input.insert","text":"","code":"dbfile.input.insert(   in.path,   in.prefix,   siteid,   startdate,   enddate,   mimetype,   formatname,   parentid = NA,   con,   hostname = PEcAn.remote::fqdn(),   allow.conflicting.dates = FALSE,   ens = FALSE )"},{"path":"/reference/dbfile.input.insert.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Insert file into tables — dbfile.input.insert","text":".path path directory containing file inserted .prefix initial portion filename vary date. include directory; specify part .path siteid id site data applicable startdate start date data stored file enddate end date data stored file mimetype mime-type file formatname name format distinguish simmilair mime-types parentid id parent input con database connection object hostname name host file stored, default name current machine allow.conflicting.dates Whether allow new input record siteid, name, format different start/end dates ens case ensembles let one file associated one input.","code":""},{"path":"/reference/dbfile.input.insert.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Insert file into tables — dbfile.input.insert","text":"data.frame id, filename pathname input requested","code":""},{"path":"/reference/dbfile.input.insert.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Insert file into tables — dbfile.input.insert","text":"write dbfiles, inputs, machines formats required data store file","code":""},{"path":"/reference/dbfile.input.insert.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Insert file into tables — dbfile.input.insert","text":"Rob Kooper, Betsy Cowdery","code":""},{"path":"/reference/dbfile.input.insert.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Insert file into tables — dbfile.input.insert","text":"","code":"if (FALSE) { # \\dontrun{   dbfile.input.insert(     in.path = 'trait.data.Rdata',     in.prefix = siteid,     startdate = startdate,     enddate = enddate,     mimetype = 'application/x-RData',     formatname = 'traits',     con = dbcon) } # }"},{"path":"/reference/dbfile.insert.html","id":null,"dir":"Reference","previous_headings":"","what":"Insert file into tables — dbfile.insert","title":"Insert file into tables — dbfile.insert","text":"Function insert file dbfiles table","code":""},{"path":"/reference/dbfile.insert.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Insert file into tables — dbfile.insert","text":"","code":"dbfile.insert(   in.path,   in.prefix,   type,   id,   con,   reuse = TRUE,   hostname = PEcAn.remote::fqdn() )"},{"path":"/reference/dbfile.insert.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Insert file into tables — dbfile.insert","text":".path Path file directory .prefix Filename prefix (including directory) type One \"Model\", \"Posterior\", \"Input\" id container_id input modified con database connection object reuse logical: record already exists, use create new one? hostname name host file stored, default name current machine","code":""},{"path":"/reference/dbfile.insert.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Insert file into tables — dbfile.insert","text":"id file written","code":""},{"path":"/reference/dbfile.insert.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Insert file into tables — dbfile.insert","text":"write dbfiles machines required data store file","code":""},{"path":"/reference/dbfile.insert.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Insert file into tables — dbfile.insert","text":"Rob Kooper, Ryan Kelly","code":""},{"path":"/reference/dbfile.insert.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Insert file into tables — dbfile.insert","text":"","code":"if (FALSE) { # \\dontrun{   dbfile.insert('somefile.txt', 'Input', 7, dbcon) } # }"},{"path":"/reference/dbfile.move.html","id":null,"dir":"Reference","previous_headings":"","what":"Move files to new location — dbfile.move","title":"Move files to new location — dbfile.move","text":"function move dbfiles - clim nc -  one location another machine update BETY","code":""},{"path":"/reference/dbfile.move.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Move files to new location — dbfile.move","text":"","code":"dbfile.move(old.dir, new.dir, file.type, siteid = NULL, register = FALSE)"},{"path":"/reference/dbfile.move.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Move files to new location — dbfile.move","text":"old.dir directory files moved new.dir directory files moved file.type type files moved siteid needed register files arent already BETY register file already BETY, registered?","code":""},{"path":"/reference/dbfile.move.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Move files to new location — dbfile.move","text":"print statement many files moved, registered, symbolic links","code":""},{"path":"/reference/dbfile.move.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Move files to new location — dbfile.move","text":"kzarada","code":""},{"path":[]},{"path":"/reference/dbfile.posterior.check.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for a file in the input/dbfiles tables — dbfile.posterior.check","title":"Check for a file in the input/dbfiles tables — dbfile.posterior.check","text":"Function check see file exists dbfiles table input","code":""},{"path":"/reference/dbfile.posterior.check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for a file in the input/dbfiles tables — dbfile.posterior.check","text":"","code":"dbfile.posterior.check(   pft,   mimetype,   formatname,   con,   hostname = PEcAn.remote::fqdn() )"},{"path":"/reference/dbfile.posterior.check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for a file in the input/dbfiles tables — dbfile.posterior.check","text":"pft name pft data applicable mimetype mime-type file formatname name format distinguish simmilair mime-types con database connection object hostname name host file stored, default name current machine","code":""},{"path":"/reference/dbfile.posterior.check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for a file in the input/dbfiles tables — dbfile.posterior.check","text":"data.frame id, filename pathname posterior requested","code":""},{"path":"/reference/dbfile.posterior.check.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check for a file in the input/dbfiles tables — dbfile.posterior.check","text":"check dbfiles, inputs, machines formats tables see file exists","code":""},{"path":"/reference/dbfile.posterior.check.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check for a file in the input/dbfiles tables — dbfile.posterior.check","text":"Rob Kooper","code":""},{"path":"/reference/dbfile.posterior.check.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check for a file in the input/dbfiles tables — dbfile.posterior.check","text":"","code":"if (FALSE) { # \\dontrun{   dbfile.posterior.check(pft, 'application/x-RData', 'traits', dbcon) } # }"},{"path":"/reference/dbfile.posterior.insert.html","id":null,"dir":"Reference","previous_headings":"","what":"Insert file into tables — dbfile.posterior.insert","title":"Insert file into tables — dbfile.posterior.insert","text":"Function insert file dbfiles table posterior","code":""},{"path":"/reference/dbfile.posterior.insert.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Insert file into tables — dbfile.posterior.insert","text":"","code":"dbfile.posterior.insert(   filename,   pft,   mimetype,   formatname,   con,   hostname = PEcAn.remote::fqdn() )"},{"path":"/reference/dbfile.posterior.insert.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Insert file into tables — dbfile.posterior.insert","text":"filename name file inserted pft name pft data applicable mimetype mime-type file formatname name format distinguish simmilair mime-types con database connection object hostname name host file stored, default name current machine","code":""},{"path":"/reference/dbfile.posterior.insert.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Insert file into tables — dbfile.posterior.insert","text":"data.frame id, filename pathname posterior requested","code":""},{"path":"/reference/dbfile.posterior.insert.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Insert file into tables — dbfile.posterior.insert","text":"write dbfiles, posteriors, machines formats require data store file","code":""},{"path":"/reference/dbfile.posterior.insert.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Insert file into tables — dbfile.posterior.insert","text":"Rob Kooper","code":""},{"path":"/reference/dbfile.posterior.insert.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Insert file into tables — dbfile.posterior.insert","text":"","code":"if (FALSE) { # \\dontrun{   dbfile.posterior.insert('trait.data.Rdata', pft, 'application/x-RData', 'traits', dbcon) } # }"},{"path":"/reference/default_hostname.html","id":null,"dir":"Reference","previous_headings":"","what":"default_hostname — default_hostname","title":"default_hostname — default_hostname","text":"Convenience function fix hostname localhost","code":""},{"path":"/reference/default_hostname.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"default_hostname — default_hostname","text":"","code":"default_hostname(hostname)"},{"path":"/reference/default_hostname.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"default_hostname — default_hostname","text":"hostname character","code":""},{"path":"/reference/default_hostname.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"default_hostname — default_hostname","text":"hostname","code":""},{"path":"/reference/derive.trait.html","id":null,"dir":"Reference","previous_headings":"","what":"Performs an arithmetic function, FUN, over a series of traits and returns the result as a derived trait. — derive.trait","title":"Performs an arithmetic function, FUN, over a series of traits and returns the result as a derived trait. — derive.trait","text":"Performs arithmetic function, FUN, series traits returns result derived trait. Traits must specified either lists single row data frames, must either single data points normally distributed. event one input traits normally distributed, resulting distribution approximated numerical simulation. output trait effectively copy first input trait modified mean, stat, n.","code":""},{"path":"/reference/derive.trait.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performs an arithmetic function, FUN, over a series of traits and returns the result as a derived trait. — derive.trait","text":"","code":"derive.trait(FUN, ..., input = list(...), var.name = NA, sample.size = 10^6)"},{"path":"/reference/derive.trait.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performs an arithmetic function, FUN, over a series of traits and returns the result as a derived trait. — derive.trait","text":"FUN arithmetic function ... traits supplied FUN input input list trait inputs. See examples var.name name use output sample.size number random samples generated rnorm normally distributed trait input","code":""},{"path":"/reference/derive.trait.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performs an arithmetic function, FUN, over a series of traits and returns the result as a derived trait. — derive.trait","text":"copy first input trait mean, stat, n reflecting derived trait","code":""},{"path":"/reference/derive.trait.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performs an arithmetic function, FUN, over a series of traits and returns the result as a derived trait. — derive.trait","text":"","code":"input <- list(x = data.frame(mean = 1, stat = 1, n = 1)) derive.trait(FUN = identity, input = input, var.name = 'x') #>        mean      stat n vname #> 1 0.9999624 0.9996339 1     x"},{"path":"/reference/derive.traits.html","id":null,"dir":"Reference","previous_headings":"","what":"Performs an arithmetic function, FUN, over a series of traits and returns the result as a derived trait. — derive.traits","title":"Performs an arithmetic function, FUN, over a series of traits and returns the result as a derived trait. — derive.traits","text":"Equivalent derive.trait(), operates series trait datasets, opposed individual trait rows. See derive.trait; information.","code":""},{"path":"/reference/derive.traits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performs an arithmetic function, FUN, over a series of traits and returns the result as a derived trait. — derive.traits","text":"","code":"derive.traits(   FUN,   ...,   input = list(...),   match.columns = c(\"citation_id\", \"site_id\", \"specie_id\"),   var.name = NA,   sample.size = 10^6 )"},{"path":"/reference/derive.traits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performs an arithmetic function, FUN, over a series of traits and returns the result as a derived trait. — derive.traits","text":"FUN arithmetic function ... trait datasets supplied FUN input input list trait inputs. See examples derive.trait match.columns event one trait dataset supplied, specifies columns identify unique data point var.name name use output sample.size traits normally distributed given","code":""},{"path":"/reference/derive.traits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performs an arithmetic function, FUN, over a series of traits and returns the result as a derived trait. — derive.traits","text":"copy first input trait modified mean, stat, n","code":""},{"path":"/reference/dplyr.count.html","id":null,"dir":"Reference","previous_headings":"","what":"Count rows of a data frame — dplyr.count","title":"Count rows of a data frame — dplyr.count","text":"Count rows data frame","code":""},{"path":"/reference/dplyr.count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count rows of a data frame — dplyr.count","text":"","code":"dplyr.count(df)"},{"path":"/reference/dplyr.count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count rows of a data frame — dplyr.count","text":"df Data frame count length","code":""},{"path":"/reference/fancy_scientific.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert number to scientific notation pretty expression — fancy_scientific","title":"Convert number to scientific notation pretty expression — fancy_scientific","text":"Convert number scientific notation pretty expression","code":""},{"path":"/reference/fancy_scientific.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert number to scientific notation pretty expression — fancy_scientific","text":"","code":"fancy_scientific(l)"},{"path":"/reference/fancy_scientific.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert number to scientific notation pretty expression — fancy_scientific","text":"l Number convert scientific notation","code":""},{"path":"/reference/fetch.stats2se.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetch data and transform stats to SE — fetch.stats2se","title":"Fetch data and transform stats to SE — fetch.stats2se","text":"Queries data trait database transforms statistics SE","code":""},{"path":"/reference/fetch.stats2se.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetch data and transform stats to SE — fetch.stats2se","text":"","code":"fetch.stats2se(connection, query)"},{"path":"/reference/fetch.stats2se.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetch data and transform stats to SE — fetch.stats2se","text":"connection connection trait database query send databse","code":""},{"path":"/reference/fetch.stats2se.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetch data and transform stats to SE — fetch.stats2se","text":"dataframe trait data","code":""},{"path":"/reference/fetch.stats2se.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fetch data and transform stats to SE — fetch.stats2se","text":"Performs query uses transformstats convert miscellaneous statistical summaries SE","code":""},{"path":[]},{"path":"/reference/fetch.stats2se.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fetch data and transform stats to SE — fetch.stats2se","text":"<unknown>","code":""},{"path":"/reference/filter_sunleaf_traits.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to filter out upper canopy leaves — filter_sunleaf_traits","title":"Function to filter out upper canopy leaves — filter_sunleaf_traits","text":"Function filter upper canopy leaves","code":""},{"path":"/reference/filter_sunleaf_traits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to filter out upper canopy leaves — filter_sunleaf_traits","text":"","code":"filter_sunleaf_traits(data, covariates)"},{"path":"/reference/filter_sunleaf_traits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to filter out upper canopy leaves — filter_sunleaf_traits","text":"data input data covariates covariate data","code":""},{"path":"/reference/filter_sunleaf_traits.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to filter out upper canopy leaves — filter_sunleaf_traits","text":"David LeBauer","code":""},{"path":"/reference/get.id.html","id":null,"dir":"Reference","previous_headings":"","what":"get.id — get.id","title":"get.id — get.id","text":"Retrieve id table matching query","code":""},{"path":"/reference/get.id.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get.id — get.id","text":"","code":"get.id(table, colnames, values, con, create = FALSE, dates = TRUE)"},{"path":"/reference/get.id.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get.id — get.id","text":"table name table colnames names one columns used clause values values queried fields corresponding colnames con database connection object, create logical: make record none found? dates Ignored. Formerly indicated whether set created_at updated_at timestamps `create` TRUE, database now always sets automatically","code":""},{"path":"/reference/get.id.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"get.id — get.id","text":"numeric","code":""},{"path":"/reference/get.id.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"get.id — get.id","text":"David LeBauer","code":""},{"path":"/reference/get.id.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"get.id — get.id","text":"","code":"if (FALSE) { # \\dontrun{ pftid <- get.id(\"pfts\", \"name\", \"salix\", con) pftid <- get.id(\"pfts\", c(\"name\", \"modeltype_id\"), c(\"ebifarm.salix\", 1), con) } # }"},{"path":"/reference/get.trait.data.html","id":null,"dir":"Reference","previous_headings":"","what":"Get trait data from the database. — get.trait.data","title":"Get trait data from the database. — get.trait.data","text":"use following items settings: - `settings$pfts` - `settings$model$type` - `settings$database$bety` - `settings$database$dbfiles` - `settings$meta.analysis$update`","code":""},{"path":"/reference/get.trait.data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get trait data from the database. — get.trait.data","text":"","code":"get.trait.data(   pfts,   modeltype,   dbfiles,   database,   forceupdate,   write = FALSE,   trait.names = NULL )"},{"path":"/reference/get.trait.data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get trait data from the database. — get.trait.data","text":"pfts list pfts get traits modeltype type model used, used distinguish different PFTs name. dbfiles location previous results found database database connection parameters (see `params` argument [db.query()]) forceupdate (Logical) `TRUE`, force database update whether needed. `FALSE`, update update needed. write (Logical) `TRUE` updated posteriors written BETYdb.  Defaults FALSE. trait.names Character vector trait names search. `NULL` (default), use traits prior least one `pfts`.","code":""},{"path":"/reference/get.trait.data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get trait data from the database. — get.trait.data","text":"list PFTs update posteriorids","code":""},{"path":"/reference/get.trait.data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get trait data from the database. — get.trait.data","text":"David LeBauer, Shawn Serbin, Alexey Shiklomanov","code":""},{"path":"/reference/get.trait.data.pft.html","id":null,"dir":"Reference","previous_headings":"","what":"Get trait data from the database for a single PFT — get.trait.data.pft","title":"Get trait data from the database for a single PFT — get.trait.data.pft","text":"Get trait data database single PFT","code":""},{"path":"/reference/get.trait.data.pft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get trait data from the database for a single PFT — get.trait.data.pft","text":"","code":"get.trait.data.pft(   pft,   modeltype,   dbfiles,   dbcon,   trait.names,   forceupdate = FALSE,   write = FALSE )"},{"path":"/reference/get.trait.data.pft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get trait data from the database for a single PFT — get.trait.data.pft","text":"pft list settings pft whose traits retrieve. See details modeltype type model used, used distinguish different pfts name. dbfiles location previous results found dbcon database connection trait.names list trait names retrieve forceupdate set true force update, auto check see update needed. write (Logical) `TRUE` updated posteriors written BETYdb.  Defaults FALSE.","code":""},{"path":"/reference/get.trait.data.pft.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get trait data from the database for a single PFT — get.trait.data.pft","text":"updated pft posteriorid","code":""},{"path":"/reference/get.trait.data.pft.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get trait data from the database for a single PFT — get.trait.data.pft","text":"`pft` list containing least `name` `outdir`, optionally `posteriorid` `constants`. BEWARE: existing files `outir` deleted!","code":""},{"path":"/reference/get.trait.data.pft.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get trait data from the database for a single PFT — get.trait.data.pft","text":"David LeBauer, Shawn Serbin, Rob Kooper","code":""},{"path":"/reference/get_machine_host.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper Function to retrieve machine host and machine informations — get_machine_host","title":"Helper Function to retrieve machine host and machine informations — get_machine_host","text":"Helper Function retrieve machine host machine informations","code":""},{"path":"/reference/get_machine_host.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper Function to retrieve machine host and machine informations — get_machine_host","text":"","code":"get_machine_host(host, con)"},{"path":"/reference/get_machine_host.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper Function to retrieve machine host and machine informations — get_machine_host","text":"host host information con database connection","code":""},{"path":"/reference/get_machine_host.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper Function to retrieve machine host and machine informations — get_machine_host","text":"list machine host machine information","code":""},{"path":"/reference/get_machine_host.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Helper Function to retrieve machine host and machine informations — get_machine_host","text":"Abhinav Pandey","code":""},{"path":"/reference/get_machine_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Get machine information from db — get_machine_info","title":"Get machine information from db — get_machine_info","text":"Get machine information db","code":""},{"path":"/reference/get_machine_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get machine information from db — get_machine_info","text":"","code":"get_machine_info(host, input.args, input.id = NULL, con = NULL)"},{"path":"/reference/get_machine_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get machine information from db — get_machine_info","text":"host host information input.args input args existing records input.id input id existing records con database connection","code":""},{"path":"/reference/get_machine_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get machine information from db — get_machine_info","text":"list machine, input, dbfile records","code":""},{"path":"/reference/get_machine_info.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get machine information from db — get_machine_info","text":"Betsy Cowdery, Michael Dietze, Ankur Desai, Tony Gardella, Luke Dramko","code":""},{"path":"/reference/get_postgres_envvars.html","id":null,"dir":"Reference","previous_headings":"","what":"Look up Postgres connection parameters from environment variables — get_postgres_envvars","title":"Look up Postgres connection parameters from environment variables — get_postgres_envvars","text":"Retrieves database connection parameters stored  environment variables known Postgres,  using defaults `...` parameters set environment.  standard PEcAn installation parameters  ever set, check anyway case need  anything unusual.","code":""},{"path":"/reference/get_postgres_envvars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Look up Postgres connection parameters from environment variables — get_postgres_envvars","text":"","code":"get_postgres_envvars(...)"},{"path":"/reference/get_postgres_envvars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Look up Postgres connection parameters from environment variables — get_postgres_envvars","text":"... defaults parameters found environment, `name = value` form","code":""},{"path":"/reference/get_postgres_envvars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Look up Postgres connection parameters from environment variables — get_postgres_envvars","text":"list connection parameters suitable passing `db.open`","code":""},{"path":"/reference/get_postgres_envvars.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Look up Postgres connection parameters from environment variables — get_postgres_envvars","text":"list environment variables check taken  [Postgres 12 manual](https://postgresql.org/docs/12/libpq-envars.html),  apply older Postgres versions well.  Note function looks environment variables control  connection parameters; retrieve variables related  per-session behavior (e.g. PGTZ, PGSYSCONFDIR).","code":""},{"path":"/reference/get_postgres_envvars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Look up Postgres connection parameters from environment variables — get_postgres_envvars","text":"","code":"host <- Sys.getenv(\"PGHOST\") # to restore environment after demo   Sys.unsetenv(\"PGHOST\")  get_postgres_envvars()$host # NULL #> NULL  get_postgres_envvars(host = \"default\", port = 5432)$host # \"default\" #> [1] \"default\"  # defaults are ignored for a variable that exists  Sys.setenv(PGHOST = \"localhost\")  get_postgres_envvars()$host # \"localhost\" #> [1] \"localhost\"  get_postgres_envvars(host = \"postgres\")$host # still \"localhost\" #> [1] \"localhost\"   # To override a set variable, edit the returned list before using it  con_parms <- get_postgres_envvars()  con_parms$host # \"localhost\" #> [1] \"localhost\"  con_parms$host <- \"postgres\"  # db.open(con_parms)   Sys.setenv(PGHOST = host)"},{"path":"/reference/get_run_ids.html","id":null,"dir":"Reference","previous_headings":"","what":"Get vector of run IDs for a given workflow ID — get_run_ids","title":"Get vector of run IDs for a given workflow ID — get_run_ids","text":"Get vector run IDs given workflow ID","code":""},{"path":"/reference/get_run_ids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get vector of run IDs for a given workflow ID — get_run_ids","text":"","code":"get_run_ids(bety, workflow_id)"},{"path":"/reference/get_run_ids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get vector of run IDs for a given workflow ID — get_run_ids","text":"bety BETYdb connection, opened `betyConnect()` workflow_id Workflow ID","code":""},{"path":"/reference/get_users.html","id":null,"dir":"Reference","previous_headings":"","what":"Get data frame of users and IDs — get_users","title":"Get data frame of users and IDs — get_users","text":"Get data frame users IDs","code":""},{"path":"/reference/get_users.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get data frame of users and IDs — get_users","text":"","code":"get_users(bety)"},{"path":"/reference/get_users.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get data frame of users and IDs — get_users","text":"bety BETYdb connection, opened `betyConnect()`","code":""},{"path":"/reference/get_var_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Get vector of variable names for a particular workflow and run ID — get_var_names","title":"Get vector of variable names for a particular workflow and run ID — get_var_names","text":"Get vector variable names particular workflow run ID","code":""},{"path":"/reference/get_var_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get vector of variable names for a particular workflow and run ID — get_var_names","text":"","code":"get_var_names(bety, workflow_id, run_id, remove_pool = TRUE)"},{"path":"/reference/get_var_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get vector of variable names for a particular workflow and run ID — get_var_names","text":"bety BETYdb connection, opened `betyConnect()` workflow_id Workflow ID run_id Run ID remove_pool logical: ignore variables 'pools' names?","code":""},{"path":"/reference/get_workflow_ids.html","id":null,"dir":"Reference","previous_headings":"","what":"Get vector of workflow IDs — get_workflow_ids","title":"Get vector of workflow IDs — get_workflow_ids","text":"Get vector workflow IDs","code":""},{"path":"/reference/get_workflow_ids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get vector of workflow IDs — get_workflow_ids","text":"","code":"get_workflow_ids(bety, query, all.ids = FALSE)"},{"path":"/reference/get_workflow_ids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get vector of workflow IDs — get_workflow_ids","text":"bety BETYdb connection, opened `betyConnect()` query Named vector list workflow IDs .ids logical: return list workflow_ids BETY database, just part query?","code":""},{"path":"/reference/insert.format.vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Insert Format and Format-Variable Records — insert.format.vars","title":"Insert Format and Format-Variable Records — insert.format.vars","text":"Insert Format Format-Variable Records","code":""},{"path":"/reference/insert.format.vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Insert Format and Format-Variable Records — insert.format.vars","text":"","code":"insert.format.vars(   con,   format_name,   mimetype_id,   notes = NULL,   header = TRUE,   skip = 0,   formats_variables = NULL,   suppress = TRUE )"},{"path":"/reference/insert.format.vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Insert Format and Format-Variable Records — insert.format.vars","text":"con SQL connection BETYdb format_name name format. Type: character string. mimetype_id id associated mimetype format. Type: integer. notes Additional description format: character string. header Boolean indicates presence header format. Defaults \"TRUE\". skip Integer indicates number lines skip header. Defaults 0. formats_variables 'tibble' consisting entries correspond columns formats-variables table. See Details information. suppress Boolean suppresses allows test existing variable id. test inconvenient applications variable_ids already known.","code":""},{"path":"/reference/insert.format.vars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Insert Format and Format-Variable Records — insert.format.vars","text":"format_id","code":""},{"path":"/reference/insert.format.vars.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Insert Format and Format-Variable Records — insert.format.vars","text":"formats_variables argument must 'tibble' structured specific format SQL query functions properly. arguments passed vectors entry correspond specific row. empty values specified NA. variable_id (Required) Vector integers. name (Optional) Vector character strings. variable name imported data need specified differs BETY variable name. unit (Optional) Vector type character string. format parseable udunits library need secified units data file differ BETY standard. storage_type (Optional) Vector character strings. Storage type need specified variable stored format expected (e.g. numeric values stored quoted character strings). Additionally, storage_type stores POSIX codes used store time variables (e.g. column 4-digit year %Y). See also [base::strptime] column_number Vector integers list column numbers associated variables dataset. Required text files lack headers.","code":""},{"path":"/reference/insert.format.vars.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Insert Format and Format-Variable Records — insert.format.vars","text":"Liam Burke (liam.burke24@gmail.com)","code":""},{"path":"/reference/insert.format.vars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Insert Format and Format-Variable Records — insert.format.vars","text":"","code":"if (FALSE) { # \\dontrun{ con <- PEcAn.DB::betyConnect()  formats_variables_tibble <- tibble::tibble(   variable_id = c(411, 135, 382),   name = c(\"NPP\", NA, \"YEAR\"),   unit = c(\"g C m-2 yr-1\", NA, NA),   storage_type = c(NA, NA, \"%Y\"),   column_number = c(2, NA, 4))  insert.format.vars(   con = con,   format_name = \"LTER-HFR-103\",   mimetype_id = 1090,   notes = \"NPP from Harvard Forest.\",   header = FALSE,   skip = 0,   formats_variables = formats_variables_tibble) } # }"},{"path":"/reference/insert_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Insert R data frame into SQL database — insert_table","title":"Insert R data frame into SQL database — insert_table","text":"First, subset matching columns. , make sure local SQL column classes match, coercing local SQL necessary (throwing error). , build SQL string insert statement. Finally, insert database.","code":""},{"path":"/reference/insert_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Insert R data frame into SQL database — insert_table","text":"","code":"insert_table(values, table, con, coerce_col_class = TRUE, drop = TRUE)"},{"path":"/reference/insert_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Insert R data frame into SQL database — insert_table","text":"values `data.frame` values write SQL database table Name target SQL table, character con Database connection object coerce_col_class logical, whether coerce local data columns SQL classes. Default = `TRUE.` drop logical. `TRUE` (default), drop columns found SQL table.","code":""},{"path":"/reference/insert_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Insert R data frame into SQL database — insert_table","text":"data frame query results","code":""},{"path":"/reference/insert_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Insert R data frame into SQL database — insert_table","text":"","code":"irisdb <- DBI::dbConnect(RSQLite::SQLite(), \":memory:\") dplyr::copy_to(irisdb, iris[1,], name = \"iris\", overwrite = TRUE) insert_table(iris[-1,], \"iris\", irisdb) #> [1] 149 dplyr::tbl(irisdb, \"iris\") #> # Source:   table<`iris`> [?? x 5] #> # Database: sqlite 3.47.1 [:memory:] #>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species #>           <dbl>       <dbl>        <dbl>       <dbl> <chr>   #>  1          5.1         3.5          1.4         0.2 setosa  #>  2          4.9         3            1.4         0.2 setosa  #>  3          4.7         3.2          1.3         0.2 setosa  #>  4          4.6         3.1          1.5         0.2 setosa  #>  5          5           3.6          1.4         0.2 setosa  #>  6          5.4         3.9          1.7         0.4 setosa  #>  7          4.6         3.4          1.4         0.3 setosa  #>  8          5           3.4          1.5         0.2 setosa  #>  9          4.4         2.9          1.4         0.2 setosa  #> 10          4.9         3.1          1.5         0.1 setosa  #> # ℹ more rows"},{"path":"/reference/load_data_single_run.html","id":null,"dir":"Reference","previous_headings":"","what":"Load data for a single run of the model — load_data_single_run","title":"Load data for a single run of the model — load_data_single_run","text":"Load data single run model","code":""},{"path":"/reference/load_data_single_run.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load data for a single run of the model — load_data_single_run","text":"","code":"load_data_single_run(bety, workflow_id, run_id)"},{"path":"/reference/load_data_single_run.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load data for a single run of the model — load_data_single_run","text":"bety BETYdb connection, opened `betyConnect()` workflow_id Workflow ID run_id Run ID","code":""},{"path":"/reference/match_colnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Match names of local data frame to SQL table — match_colnames","title":"Match names of local data frame to SQL table — match_colnames","text":"Match names local data frame SQL table","code":""},{"path":"/reference/match_colnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Match names of local data frame to SQL table — match_colnames","text":"","code":"match_colnames(values, table, con)"},{"path":"/reference/match_colnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Match names of local data frame to SQL table — match_colnames","text":"values `data.frame` values write SQL database table Name target SQL table, character con Database connection object","code":""},{"path":"/reference/match_dbcols.html","id":null,"dir":"Reference","previous_headings":"","what":"Match column names and classes between local and SQL table — match_dbcols","title":"Match column names and classes between local and SQL table — match_dbcols","text":"Match column names classes local SQL table","code":""},{"path":"/reference/match_dbcols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Match column names and classes between local and SQL table — match_dbcols","text":"","code":"match_dbcols(values, table, con, coerce_col_class = TRUE, drop = TRUE)"},{"path":"/reference/match_dbcols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Match column names and classes between local and SQL table — match_dbcols","text":"values `data.frame` values write SQL database table Name target SQL table, character con Database connection object coerce_col_class logical, whether coerce local data columns SQL classes. Default = `TRUE.` drop logical. `TRUE` (default), drop columns found SQL table.","code":""},{"path":"/reference/match_dbcols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Match column names and classes between local and SQL table — match_dbcols","text":"`values` `data.frame` column names classes matched SQL","code":""},{"path":"/reference/met_inputs.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve available met inputs for the given site, model, and hostname — met_inputs","title":"Retrieve available met inputs for the given site, model, and hostname — met_inputs","text":"identical query performed `web/03-inputs.php` populate list available sites. may useful debugging, otherwise replicating PEcAn web interface behavior.","code":""},{"path":"/reference/met_inputs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve available met inputs for the given site, model, and hostname — met_inputs","text":"","code":"met_inputs(dbcon, site_id, model_id, hostname)"},{"path":"/reference/met_inputs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve available met inputs for the given site, model, and hostname — met_inputs","text":"dbcon Database connection object site_id Site ID (`sites` table) model_id Model ID (`models`) table hostname Hostname machine","code":""},{"path":"/reference/met_inputs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve available met inputs for the given site, model, and hostname — met_inputs","text":"`data.frame` available met inputs","code":""},{"path":"/reference/met_inputs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Retrieve available met inputs for the given site, model, and hostname — met_inputs","text":"Alexey Shiklomanov","code":""},{"path":"/reference/ncdays2date.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert netcdf number of days to a datetime — ncdays2date","title":"Convert netcdf number of days to a datetime — ncdays2date","text":"Convert netcdf number days datetime","code":""},{"path":"/reference/ncdays2date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert netcdf number of days to a datetime — ncdays2date","text":"","code":"ncdays2date(time, unit)"},{"path":"/reference/ncdays2date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert netcdf number of days to a datetime — ncdays2date","text":"time number time units elapsed since origin unit string containing CF-style time unit including origin (e.g. \"days since 2010-01-01\")","code":""},{"path":"/reference/pft.add.spp.html","id":null,"dir":"Reference","previous_headings":"","what":"Associate species with a PFT. — pft.add.spp","title":"Associate species with a PFT. — pft.add.spp","text":"adds list species pft based USDA Plants acronyms","code":""},{"path":"/reference/pft.add.spp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Associate species with a PFT. — pft.add.spp","text":"","code":"pft.add.spp(pft, acronym = NULL, ID = NULL, test = TRUE, con = NULL, ...)"},{"path":"/reference/pft.add.spp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Associate species with a PFT. — pft.add.spp","text":"pft String name PFT database acronym Specie's Symbols. see http://plants.usda.gov ID Species IDs Bety. can provide either IDs Symbols input, provide ID acronym, acronym used. test Runs function test mode.  species actually added, checks run existing species-PFT pairs, unmatched acronyms, missing species, duplicate species con Database connection object. ... optional arguements connecting database (e.g. password, user name, database)","code":""},{"path":"/reference/pft.add.spp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Associate species with a PFT. — pft.add.spp","text":"Function return value print diagnostic statements.","code":""},{"path":"/reference/pft.add.spp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Associate species with a PFT. — pft.add.spp","text":"function used add PFT-Species pairs database table 'pfts_species'.  initial implementation PFT defined already species added based USDA Symbol (genus/species acronym).  Multiple species can added one PFT time. Symbols object ","code":""},{"path":"/reference/pft.add.spp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Associate species with a PFT. — pft.add.spp","text":"Michael C. Dietze, Dongchen Zhang","code":""},{"path":"/reference/query.covariates.html","id":null,"dir":"Reference","previous_headings":"","what":"Queries covariates from database for a given vector of trait id's — query.covariates","title":"Queries covariates from database for a given vector of trait id's — query.covariates","text":"Queries covariates database given vector trait id's","code":""},{"path":"/reference/query.covariates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Queries covariates from database for a given vector of trait id's — query.covariates","text":"","code":"query.covariates(trait.ids, con = NULL, ...)"},{"path":"/reference/query.covariates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Queries covariates from database for a given vector of trait id's — query.covariates","text":"trait.ids list trait ids con database connection ... extra arguments","code":""},{"path":"/reference/query.covariates.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Queries covariates from database for a given vector of trait id's — query.covariates","text":"David LeBauer","code":""},{"path":"/reference/query.data.html","id":null,"dir":"Reference","previous_headings":"","what":"Query data and transform stats to SE by calling fetch.stats2se; — query.data","title":"Query data and transform stats to SE by calling fetch.stats2se; — query.data","text":"Function query data database specific species convert stat SE","code":""},{"path":"/reference/query.data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query data and transform stats to SE by calling fetch.stats2se; — query.data","text":"","code":"query.data(   trait,   spstr,   con,   extra.columns = paste(\"ST_X(ST_CENTROID(sites.geometry)) AS lon,\",     \"ST_Y(ST_CENTROID(sites.geometry)) AS lat, \"),   store.unconverted = FALSE,   ids_are_cultivars = FALSE,   ... )"},{"path":"/reference/query.data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query data and transform stats to SE by calling fetch.stats2se; — query.data","text":"trait trait query database spstr IDs species query , single comma-separated string con database connection extra.columns query terms pass . unspecified, retrieves latitude longitude store.unconverted determines whether copy mean stat fields returned _unconverted appended column names ids_are_cultivars TRUE, ids vector cultivar IDs, otherwise species IDs ... extra arguments","code":""},{"path":[]},{"path":"/reference/query.data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Query data and transform stats to SE by calling fetch.stats2se; — query.data","text":"David LeBauer, Carl Davidson","code":""},{"path":"/reference/query.file.path.html","id":null,"dir":"Reference","previous_headings":"","what":"Get file path given id and machine — query.file.path","title":"Get file path given id and machine — query.file.path","text":"Get file path given id machine","code":""},{"path":"/reference/query.file.path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get file path given id and machine — query.file.path","text":"","code":"query.file.path(input.id, host_name, con)"},{"path":"/reference/query.file.path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get file path given id and machine — query.file.path","text":"input.id database id file (\"container\") find host_name character: machine file lives con : database connection","code":""},{"path":"/reference/query.file.path.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get file path given id and machine — query.file.path","text":"Betsy Cowdery","code":""},{"path":"/reference/query.format.vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Look up names and units of input variables from a format id or input id — query.format.vars","title":"Look up names and units of input variables from a format id or input id — query.format.vars","text":"Look names units input variables format id input id","code":""},{"path":"/reference/query.format.vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Look up names and units of input variables from a format id or input id — query.format.vars","text":"","code":"query.format.vars(bety, input.id = NA, format.id = NA, var.ids = NA)"},{"path":"/reference/query.format.vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Look up names and units of input variables from a format id or input id — query.format.vars","text":"bety database connection input.id, format.id numeric. Defaults format.id provided var.ids optional vector variable IDs. provided, limits results variables","code":""},{"path":"/reference/query.format.vars.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Look up names and units of input variables from a format id or input id — query.format.vars","text":"Betsy Cowdery, Ankur Desai, Istem Fer","code":""},{"path":"/reference/query.pft_cultivars.html","id":null,"dir":"Reference","previous_headings":"","what":"Select cultivars associated with a PFT — query.pft_cultivars","title":"Select cultivars associated with a PFT — query.pft_cultivars","text":"Given PFT name optionally modeltype, finds pft_id returns cultivars associated .","code":""},{"path":"/reference/query.pft_cultivars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select cultivars associated with a PFT — query.pft_cultivars","text":"","code":"query.pft_cultivars(pft, modeltype = NULL, con)"},{"path":"/reference/query.pft_cultivars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select cultivars associated with a PFT — query.pft_cultivars","text":"pft string pft name modeltype type model used, used distinguish different pfts name. con database connection","code":""},{"path":"/reference/query.pft_cultivars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select cultivars associated with a PFT — query.pft_cultivars","text":"tibble containing names ids cultivar   species comes ","code":""},{"path":"/reference/query.pft_cultivars.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Select cultivars associated with a PFT — query.pft_cultivars","text":"PFT allowed associated species associated cultivars, . function returns results, try checking PFT query.pft_species instead. Note cultivars associated one PFT ** allowed come multiple species, desired.","code":""},{"path":"/reference/query.pft_species.html","id":null,"dir":"Reference","previous_headings":"","what":"Query species given pft name — query.pft_species","title":"Query species given pft name — query.pft_species","text":"select plant id's associated pft","code":""},{"path":"/reference/query.pft_species.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query species given pft name — query.pft_species","text":"","code":"query.pft_species(pft, modeltype = NULL, con)"},{"path":"/reference/query.pft_species.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query species given pft name — query.pft_species","text":"pft string pft name modeltype type model used, used distinguish different pfts name. con database connection","code":""},{"path":"/reference/query.pft_species.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query species given pft name — query.pft_species","text":"data.frame containing id, genus, species, scientificname species associated pft","code":""},{"path":"/reference/query.pft_species.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Query species given pft name — query.pft_species","text":"David LeBauer","code":""},{"path":"/reference/query.pft_species.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query species given pft name — query.pft_species","text":"","code":"if (FALSE) { # \\dontrun{ query.pft_species('ebifarm.pavi') query.pft_species(settings = read.settings(\"pecan.xml\")) } # }"},{"path":"/reference/query.priors.html","id":null,"dir":"Reference","previous_headings":"","what":"Query Priors — query.priors","title":"Query Priors — query.priors","text":"Query priors associated plant functional type set traits.","code":""},{"path":"/reference/query.priors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query Priors — query.priors","text":"","code":"query.priors(pft, trstr = NULL, con = NULL, ...)"},{"path":"/reference/query.priors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query Priors — query.priors","text":"pft ID number PFT database trstr String traits query priors . passed character vector, concatenated single string using [PEcAn.utils::vecpaste()]. con Database connection object. ... Optional arguments connecting database (e.g. password, user name, database).","code":""},{"path":"/reference/query.priors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query Priors — query.priors","text":"`data.frame` priors trait given PFT.","code":""},{"path":"/reference/query.priors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Query Priors — query.priors","text":"neither `con` `...` provided, try   connect BETY using `settings` object current   environment.","code":""},{"path":"/reference/query.priors.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Query Priors — query.priors","text":"David LeBauer, Alexey Shiklomanov","code":""},{"path":"/reference/query.priors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query Priors — query.priors","text":"","code":"if (FALSE) { # \\dontrun{   con <- db.open(...)   query.priors(\"ebifarm.pavi\", c(\"SLA\", \"Vcmax\", \"leaf_width\"), con = con) } # }"},{"path":"/reference/query.site.html","id":null,"dir":"Reference","previous_headings":"","what":"Given site_id, return site table — query.site","title":"Given site_id, return site table — query.site","text":"Given site_id, return site table","code":""},{"path":"/reference/query.site.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Given site_id, return site table — query.site","text":"","code":"query.site(site.id, con)"},{"path":"/reference/query.site.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Given site_id, return site table — query.site","text":"site.id id site con : database connection","code":""},{"path":"/reference/query.site.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Given site_id, return site table — query.site","text":"Betsy Cowdery","code":""},{"path":"/reference/query.trait.data.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract trait data from database — query.trait.data","title":"Extract trait data from database — query.trait.data","text":"Extracts data database given trait set species, converts statistics summary statistics, prepares dataframe use meta-analysis. Vcmax SLA data, data collected  April July queried, data collected top canopy (canopy height > 0.66). Vcmax root_respiration_rate, data scaled converted measurement temperature \\(25^oC\\) via arrhenius equation.","code":""},{"path":"/reference/query.trait.data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract trait data from database — query.trait.data","text":"","code":"query.trait.data(   trait,   spstr,   con = NULL,   update.check.only = FALSE,   ids_are_cultivars = FALSE,   ... )"},{"path":"/reference/query.trait.data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract trait data from database — query.trait.data","text":"trait trait name used database, stored variables.name spstr species.id integer string integers associated species con database connection object update.check.TRUE, returns results print summaries ids_are_cultivars TRUE, IDs spstr cultivar IDs, otherwise species IDs. Passed query.data ... unused currently","code":""},{"path":"/reference/query.trait.data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract trait data from database — query.trait.data","text":"dataframe ready use meta-analysis","code":""},{"path":"/reference/query.trait.data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract trait data from database — query.trait.data","text":"David LeBauer, Carl Davidson, Shawn Serbin","code":""},{"path":"/reference/query.trait.data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract trait data from database — query.trait.data","text":"","code":"if (FALSE) { # \\dontrun{ settings <- read.settings() query.trait.data(\"Vcmax\", \"938\", con = con) } # }"},{"path":"/reference/query.traits.html","id":null,"dir":"Reference","previous_headings":"","what":"Query trait data — query.traits","title":"Query trait data — query.traits","text":"Query available trait data associated given pft list traits","code":""},{"path":"/reference/query.traits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query trait data — query.traits","text":"","code":"query.traits(   ids,   priors,   con,   update.check.only = FALSE,   ids_are_cultivars = FALSE )"},{"path":"/reference/query.traits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query trait data — query.traits","text":"ids vector species cultivar id's trait database priors vector parameters priors specified con database connection object update.check.TRUE, returns results print summaries ids_are_cultivars TRUE, ids vector cultivar IDs, otherwise species IDs","code":""},{"path":"/reference/query.traits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query trait data — query.traits","text":"list dataframes, data one trait","code":""},{"path":[]},{"path":"/reference/query.traits.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Query trait data — query.traits","text":"David LeBauer, Carl Davidson, Shawn Serbin","code":""},{"path":"/reference/query.traits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query trait data — query.traits","text":"","code":"if (FALSE) { # \\dontrun{ con <- db.open(your_settings_here) species <- query.pft_species('ebifarm.c4crop') spstr <- vecpaste(species$id) trvec <- c('leafN', 'SLA') trait.data <- query.traits(spstr, trvec, con) } # }"},{"path":"/reference/query.yields.html","id":null,"dir":"Reference","previous_headings":"","what":"Query yield data and transform stats to SE by calling fetch.stats2se; — query.yields","title":"Query yield data and transform stats to SE by calling fetch.stats2se; — query.yields","text":"Function query yields data database specific species convert stat SE","code":""},{"path":"/reference/query.yields.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query yield data and transform stats to SE by calling fetch.stats2se; — query.yields","text":"","code":"query.yields(   trait = \"yield\",   spstr,   extra.columns = \"\",   con = NULL,   ids_are_cultivars = FALSE,   ... )"},{"path":"/reference/query.yields.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query yield data and transform stats to SE by calling fetch.stats2se; — query.yields","text":"trait yield trait query spstr species query yield data extra.columns query terms pass . Optional con database connection ids_are_cultivars TRUE, spstr contains cultivar IDs, otherwise species IDs ... extra arguments","code":""},{"path":[]},{"path":"/reference/query.yields.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Query yield data and transform stats to SE by calling fetch.stats2se; — query.yields","text":"<unknown>","code":""},{"path":"/reference/query_pfts.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve PFT ID, name, and type from BETY — query_pfts","title":"Retrieve PFT ID, name, and type from BETY — query_pfts","text":"Retrieve PFT ID, name, type BETY","code":""},{"path":"/reference/query_pfts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve PFT ID, name, and type from BETY — query_pfts","text":"","code":"query_pfts(dbcon, pft_names, modeltype = NULL, strict = FALSE)"},{"path":"/reference/query_pfts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve PFT ID, name, and type from BETY — query_pfts","text":"dbcon Database connection object pft_names character vector PFT names modeltype character. specified, returns PFTs matching modeltype. NULL, considers modeltypes. strict (Logical) `TRUE`, throw error input `pft_names/ids` `traits` missing output. `FALSE` (default), throw warning.","code":""},{"path":"/reference/query_pfts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve PFT ID, name, and type from BETY — query_pfts","text":"`data.frame` containing PFT ID (`id`), type (`pft_type`),   name (`name`).","code":""},{"path":"/reference/query_pfts.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Retrieve PFT ID, name, and type from BETY — query_pfts","text":"Alexey Shiklomanov, Chris Black","code":""},{"path":"/reference/query_priors.html","id":null,"dir":"Reference","previous_headings":"","what":"Query priors using prepared statements — query_priors","title":"Query priors using prepared statements — query_priors","text":"Query priors using prepared statements","code":""},{"path":"/reference/query_priors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query priors using prepared statements — query_priors","text":"","code":"query_priors(   pft_names = NULL,   traits = NULL,   pft_ids = NULL,   expand = TRUE,   strict = FALSE,   ... )"},{"path":"/reference/query_priors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query priors using prepared statements — query_priors","text":"pft_names Character vector PFT names (`name` column BETY `pfts` table). pass `pft_ids`. traits Character vector trait names (`name` column BETY `traits` table). `NULL` (default), return information traits available PFT. pft_ids Numeric vector PFT IDs (`id` column BETY `pfts` table). pass `pft_names`. expand (Logical) `TRUE` (default), search every trait-PFT combination. `FALSE`, assume input traits PFTs paired. strict (Logical) `TRUE`, throw error input `pft_names/ids` `traits` missing output. `FALSE` (default), throw warning. ... Additional arguments [db.query()]","code":""},{"path":"/reference/query_priors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query priors using prepared statements — query_priors","text":"`data.frame` containing prior information given   PFTs traits.","code":""},{"path":"/reference/query_priors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query priors using prepared statements — query_priors","text":"","code":"if (FALSE) { # \\dontrun{   con <- db.open(...)    # No trait provided, so return all available traits   pdat <- query_priors(     c(\"temperate.Early_Hardwood\", \"temperate.North_Mid_Hardwood\",       \"temperate.Late_Hardwood\"),     con = con   )    # Traits provided, so restrict to only those traits. Note that   # because `expand = TRUE`, this will search for these traits for   # every PFT.   pdat2 <- query_priors(     c(\"Optics.Temperate_Early_Hardwood\",       \"Optics.Temperate_Mid_Hardwood\",       \"Optics.Temperate_Late_Hardwood\"),     c(\"leaf_reflect_vis\", \"leaf_reflect_nir\"),     con = con   )    # With `expand = FALSE`, search the first trait for the first PFT,   # the second trait for the second PFT, etc. Note that this means   # PFT and trait input vectors must be the same length.   pdat2 <- query_priors(     c(\"Optics.Temperate_Early_Hardwood\",       \"Optics.Temperate_Early_Hardwood\",       \"Optics.Temperate_Mid_Hardwood\",       \"Optics.Temperate_Late_Hardwood\"),     c(\"leaf_reflect_vis\",       \"leaf_reflect_nir\",       \"leaf_reflect_vis\",       \"leaf_reflect_nir\"),     con = con   ) } # }"},{"path":"/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. magrittr %>%","code":""},{"path":"/reference/runs.html","id":null,"dir":"Reference","previous_headings":"","what":"Get table of runs corresponding to a workflow — runs","title":"Get table of runs corresponding to a workflow — runs","text":"Get table runs corresponding workflow","code":""},{"path":"/reference/runs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get table of runs corresponding to a workflow — runs","text":"","code":"runs(bety, workflow_id)"},{"path":"/reference/runs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get table of runs corresponding to a workflow — runs","text":"bety BETYdb connection, opened `betyConnect()` workflow_id Workflow ID","code":""},{"path":"/reference/search_reference_single.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform crossref search for a single reference — search_reference_single","title":"Perform crossref search for a single reference — search_reference_single","text":"Requires `rcrossref` package.","code":""},{"path":"/reference/search_reference_single.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform crossref search for a single reference — search_reference_single","text":"","code":"search_reference_single(query, limit = 1, min_score = 85)"},{"path":"/reference/search_reference_single.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform crossref search for a single reference — search_reference_single","text":"query Citation string (length 1) search DOI limit Number results return min_score Minimum match score. Default (85) fairly strict.","code":""},{"path":"/reference/search_reference_single.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform crossref search for a single reference — search_reference_single","text":"`data.frame` containing crossref information converted match bety citations table.","code":""},{"path":"/reference/search_references.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform crossref search for a list of references — search_references","title":"Perform crossref search for a list of references — search_references","text":"Requires `rcrossref` package.","code":""},{"path":"/reference/search_references.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform crossref search for a list of references — search_references","text":"","code":"search_references(queries, ...)"},{"path":"/reference/search_references.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform crossref search for a list of references — search_references","text":"queries Character vector queries ... Arguments passed search_reference_single query Citation string (length 1) search DOI min_score Minimum match score. Default (85) fairly strict. limit Number results return","code":""},{"path":"/reference/search_references.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform crossref search for a list of references — search_references","text":"`data.frame` containing crossref information converted match bety citations table.","code":""},{"path":"/reference/stamp_started.html","id":null,"dir":"Reference","previous_headings":"","what":"Stamp start and stop times of runs — stamp_started","title":"Stamp start and stop times of runs — stamp_started","text":"Stamp start stop times runs","code":""},{"path":"/reference/stamp_started.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stamp start and stop times of runs — stamp_started","text":"","code":"stamp_started(con, run)  stamp_finished(con, run)"},{"path":"/reference/stamp_started.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stamp start and stop times of runs — stamp_started","text":"con BETY database connection run (numeric) run ID","code":""},{"path":"/reference/stamp_started.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stamp start and stop times of runs — stamp_started","text":"`NULL`","code":""},{"path":"/reference/symmetric_setdiff.html","id":null,"dir":"Reference","previous_headings":"","what":"Symmetric set difference of two data frames — symmetric_setdiff","title":"Symmetric set difference of two data frames — symmetric_setdiff","text":"Symmetric set difference two data frames","code":""},{"path":"/reference/symmetric_setdiff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Symmetric set difference of two data frames — symmetric_setdiff","text":"","code":"symmetric_setdiff(   x,   y,   xname = \"x\",   yname = \"y\",   namecol = \"source\",   simplify_types = TRUE )"},{"path":"/reference/symmetric_setdiff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Symmetric set difference of two data frames — symmetric_setdiff","text":"x, y `data.frame`s compare xname Label data x y. Default = \"x\" yname Label data y x. Default = \"y\" namecol Name label column. Default = \"source\". simplify_types (Logical) `TRUE`, coerce anything numeric character, facilitate comparison.","code":""},{"path":"/reference/symmetric_setdiff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Symmetric set difference of two data frames — symmetric_setdiff","text":"`data.frame` data common x y, additional   column (`namecol`) indicating whether data x   (`xname`) y (`yname`)","code":""},{"path":"/reference/symmetric_setdiff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Symmetric set difference of two data frames — symmetric_setdiff","text":"","code":"xdf <- data.frame(a = c(\"a\", \"b\", \"c\"),                   b = c(1, 2, 3),                   stringsAsFactors = FALSE) ydf <- data.frame(a = c(\"a\", \"b\", \"d\"),                   b = c(1, 2.5, 3),                   stringsAsFactors = FALSE) symmetric_setdiff(xdf, ydf) #>   source a   b #> 1      x b 2.0 #> 2      x c 3.0 #> 3      y b 2.5 #> 4      y d 3.0"},{"path":"/reference/take.samples.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from normal distribution, given summary stats — take.samples","title":"Sample from normal distribution, given summary stats — take.samples","text":"sample normal distribution, given summary stats","code":""},{"path":"/reference/take.samples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from normal distribution, given summary stats — take.samples","text":"","code":"take.samples(summary, sample.size = 10^6)"},{"path":"/reference/take.samples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from normal distribution, given summary stats — take.samples","text":"summary data.frame values mean sd sample.size number samples take","code":""},{"path":"/reference/take.samples.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from normal distribution, given summary stats — take.samples","text":"sample length sample.size","code":""},{"path":"/reference/take.samples.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Sample from normal distribution, given summary stats — take.samples","text":"David LeBauer, Carl Davidson","code":""},{"path":"/reference/take.samples.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from normal distribution, given summary stats — take.samples","text":"","code":"## return the mean when stat = NA take.samples(summary = data.frame(mean = 10, stat = NA)) #> [1] 10 ## return vector of length \\code{sample.size} from N(mean,stat) take.samples(summary = data.frame(mean = 10, stat = 10), sample.size = 10) #>  [1] 22.6295428  6.7376664 23.2979926 22.7242932 14.1464143 -5.3995004 #>  [7]  0.7143297  7.0527955  9.9423283 34.0465339"},{"path":"/reference/try2sqlite.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert TRY text file to SQLite database — try2sqlite","title":"Convert TRY text file to SQLite database — try2sqlite","text":"TRY file huge unnecessarily long, makes difficult work . resulting SQLite database much smaller disk, can read much faster thanks lazy evaluation.","code":""},{"path":"/reference/try2sqlite.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert TRY text file to SQLite database — try2sqlite","text":"","code":"try2sqlite(try_files, sqlite_file = \"try.sqlite\")"},{"path":"/reference/try2sqlite.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert TRY text file to SQLite database — try2sqlite","text":"try_files Character vector file names containing TRY data. Multiple files combined `data.table::rbindlist`. sqlite_file Target SQLite database file name, character.","code":""},{"path":"/reference/try2sqlite.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert TRY text file to SQLite database — try2sqlite","text":"resulting TRY SQLite database contains following tables:  - `values` – actual TRY data. Links tables ID columns.  - `traits` – Description trait data names. Links `values` `DataID`. Similar BETY `variables` table.  - `datasets` – Description datasets references/citations. Links `values` `DatasetID` `ReferenceID`.  - `species` – Species. Links `values` `AccSpeciesID`.","code":""},{"path":"/reference/update_ensemble_writes.html","id":null,"dir":"Reference","previous_headings":"","what":"Insert or Update Database Records for New or Modified Input Data — update_ensemble_writes","title":"Insert or Update Database Records for New or Modified Input Data — update_ensemble_writes","text":"function called internally [convert_input()] insert update **input** **dbfile** records PEcAn BETY database one data-conversion download functions produced local remote files. specifically intended use output data-conversion functions called [convert_input()] (e.g. various \"download_X\" \"met2model_X\" functions), can adapted return structure matches requirements .","code":""},{"path":"/reference/update_ensemble_writes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Insert or Update Database Records for New or Modified Input Data — update_ensemble_writes","text":"","code":"update_ensemble_writes(   result,   con,   start_date,   end_date,   overwrite,   insert.new.file,   input.args,   machine,   mimetype,   formatname,   allow.conflicting.dates,   ensemble,   ensemble_name,   existing.input,   existing.dbfile,   input )"},{"path":"/reference/update_ensemble_writes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Insert or Update Database Records for New or Modified Input Data — update_ensemble_writes","text":"result list data frames, data frame corresponding one piece \"chunk\" newly-created data. Typically, data frames produced function specified `convert_input(..., fcn=...)`. data frame must contain least: file Absolute file path(s) newly created file(s). dbfile.name base filename(s) (without leading path) corresponding file. Additional columns allowed unused function. con database connection object (returned , e.g., dbConnect). start_date Date character. start date data (UTC). Acceptable types include Date objects (`.Date`) character strings can parsed Date via standard R conversions. end_date Date character. end date data (UTC). Acceptable types include Date objects (`.Date`) character strings can parsed Date via standard R conversions. overwrite logical. `TRUE`, existing database records files input date range overwritten new files. `FALSE`, existing files preserved. insert.new.file logical. `TRUE`, forces creation new **dbfile** entry even existing entry found. Typically used forecast ensemble data may partially present. input.args list. passed [convert_input()] contains auxiliary arguments settings passed along internally. may include items `newsite` (integer site ID), among others. exact contents strictly defined typically include arguments provided `convert_input()`. machine data.frame. Single row describing machine new data resides. typically columns like `id` `hostname`, indicating corresponding row BETY's `machines` table. mimetype character. String indicating file's MIME type (e.g. `\"text/csv\"`, `\"application/x-netcdf\"`, etc.). formatname character. String describing file format (listed BETYdb's `formats` table). example `\"CF Meteorology\"`. allow.conflicting.dates logical. `TRUE`, allows creation insertion new file records even date range overlaps existing records. `FALSE`, overlapping ranges may cause errors disallowed. ensemble integer logical. integer > 1, indicates multiple ensemble members generated (often forecast data) member may need separate database entries. `FALSE`, data ensemble. ensemble_name character. String providing descriptive label identifier ensemble member. Typically used `convert_input()` called iteratively member. existing.input data.frame. Possibly zero rows representing current record(s) `inputs` table match (partially match) data added. matching record exists, empty data frame supplied. existing.dbfile data.frame. Possibly zero rows representing current record(s) `dbfiles` table match (partially match) data added. matching record exists, empty data frame supplied. input data.frame. Single row parent input record BETYdb, typically including columns like `id`, `start_date`, `end_date`, etc. new data derived existing input, links `parent_id` column new entries.","code":""},{"path":"/reference/update_ensemble_writes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Insert or Update Database Records for New or Modified Input Data — update_ensemble_writes","text":"list two elements: input.id numeric vector new (updated) input record IDs. dbfile.id numeric vector new (updated) dbfile record IDs.","code":""},{"path":"/reference/update_ensemble_writes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Insert or Update Database Records for New or Modified Input Data — update_ensemble_writes","text":"Insert Update Database Records New Modified Input Data function consolidates final step adding updating records BETY database reflect newly created data files. either updates existing `input` `dbfile` records creates new records, depending provided arguments (`overwrite`, `insert.new.file`, etc.) whether matching record already exists. Typically, records represent model-ready meteorological environmental data, format conversion downloading taken place [convert_input()].","code":""},{"path":"/reference/update_ensemble_writes.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Insert or Update Database Records for New or Modified Input Data — update_ensemble_writes","text":"Betsy Cowdery, Michael Dietze, Ankur Desai, Tony Gardella, Luke Dramko","code":""},{"path":"/reference/var_names_all.html","id":null,"dir":"Reference","previous_headings":"","what":"Get vector of variable names for a particular workflow and run ID — var_names_all","title":"Get vector of variable names for a particular workflow and run ID — var_names_all","text":"Get vector variable names particular workflow run ID","code":""},{"path":"/reference/var_names_all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get vector of variable names for a particular workflow and run ID — var_names_all","text":"","code":"var_names_all(bety, workflow_id, run_id)"},{"path":"/reference/var_names_all.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get vector of variable names for a particular workflow and run ID — var_names_all","text":"bety BETYdb connection, opened `betyConnect()` workflow_id Workflow ID run_id Run ID","code":""},{"path":"/reference/workflow.html","id":null,"dir":"Reference","previous_headings":"","what":"Get single workflow by workflow_id — workflow","title":"Get single workflow by workflow_id — workflow","text":"Get single workflow workflow_id","code":""},{"path":"/reference/workflow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get single workflow by workflow_id — workflow","text":"","code":"workflow(bety, workflow_id)"},{"path":"/reference/workflow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get single workflow by workflow_id — workflow","text":"bety BETYdb connection, opened `betyConnect()` workflow_id Workflow ID","code":""},{"path":"/reference/workflows.html","id":null,"dir":"Reference","previous_headings":"","what":"list of workflows that exist — workflows","title":"list of workflows that exist — workflows","text":"list workflows exist","code":""},{"path":"/reference/workflows.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"list of workflows that exist — workflows","text":"","code":"workflows(bety, ensemble = FALSE)"},{"path":"/reference/workflows.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"list of workflows that exist — workflows","text":"bety BETYdb connection, opened `betyConnect()` ensemble Logical. Use workflows ensembles table.","code":""},{"path":[]},{"path":"/news/index.html","id":"license-change-1-8-1","dir":"Changelog","previous_headings":"","what":"License change","title":"PEcAn.DB 1.8.1","text":"PEcAn.DB now distributed BSD three-clause license instead NCSA Open Source license.","code":""},{"path":"/news/index.html","id":"changed-1-8-1","dir":"Changelog","previous_headings":"","what":"Changed","title":"PEcAn.DB 1.8.1","text":"Fixed several cases dbfile.input.insert continued instead returning early Removed support Browndog service defunct","code":""},{"path":[]},{"path":"/news/index.html","id":"added-1-8-0","dir":"Changelog","previous_headings":"","what":"Added","title":"PEcAn.DB 1.8.0","text":"New functions stamp_started stamp_finished, used record start end time model runs database. used live PEcAn.remote moved resolve circular dependency. New function convert_input, used convert formats reusing existing files possible. previously lived package PEcAn.utils, moved simplify dependencies. (#3026; @nanu1605) get.trait.data gains new argument write (default FALSE), passed get.trait.data.pft (@Aariq, #3065).","code":""},{"path":[]},{"path":"/news/index.html","id":"removed-1-7-2","dir":"Changelog","previous_headings":"","what":"Removed","title":"PEcAn.DB 1.7.2","text":"rename_jags_columns() removed PEcAn.DB now available package PEcAn.MA (#2805, @moki1202).","code":""},{"path":"/news/index.html","id":"pecandb-171","dir":"Changelog","previous_headings":"","what":"PEcAn.DB 1.7.1","title":"PEcAn.DB 1.7.1","text":"changes 1.7.1 earlier recorded single file PEcAn packages; please see https://github.com/PecanProject/pecan/blob/v1.7.1/CHANGELOG.md details.","code":""}]
